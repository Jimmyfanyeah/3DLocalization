{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from cmath import inf\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import socket\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import decode.evaluation\n",
    "import decode.neuralfitter\n",
    "import decode.neuralfitter.coord_transform\n",
    "import decode.neuralfitter.utils\n",
    "import decode.simulation\n",
    "import decode.utils\n",
    "# from decode.neuralfitter.train.random_simulation import setup_random_simulation\n",
    "from decode.neuralfitter.utils import log_train_val_progress\n",
    "from decode.utils.checkpoint import CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Training Args')\n",
    "\n",
    "    parser.add_argument('-i', '--device', default=None, \n",
    "                        help='Specify the device string (cpu, cuda, cuda:0) and overwrite param.',\n",
    "                        type=str)\n",
    "\n",
    "    parser.add_argument('-p', '--param_file', default=None,\n",
    "                        help='Specify your parameter file (.yml or .json).', type=str)\n",
    "\n",
    "    parser.add_argument('-w', '--num_worker_override',default=None,\n",
    "                        help='Override the number of workers for the dataloaders.',\n",
    "                        type=int)\n",
    "\n",
    "    parser.add_argument('-n', '--no_log', default=False, action='store_true',\n",
    "                        help='Set no log if you do not want to log the current run.')\n",
    "\n",
    "    parser.add_argument('-c', '--log_comment', default=None,\n",
    "                        help='Add a log_comment to the run.')\n",
    "\n",
    "    parser.add_argument('-d', '--data_path_override', default=None,\n",
    "                        help='Specify your path to data', type=str)\n",
    "\n",
    "    parser.add_argument('-is', '--img_size_override', default=None,\n",
    "                        help='Override img size', type=int)\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    # args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_trainer(logger, model_out, ckpt_path, device, param):\n",
    "    \"\"\"Set model, optimiser, loss and schedulers\"\"\"\n",
    "    models_available = {\n",
    "        'SigmaMUNet': decode.neuralfitter.models.SigmaMUNet,\n",
    "        'DoubleMUnet': decode.neuralfitter.models.model_param.DoubleMUnet,\n",
    "        'SimpleSMLMNet': decode.neuralfitter.models.model_param.SimpleSMLMNet,\n",
    "    }\n",
    "\n",
    "    model = models_available[param.HyperParameter.architecture]\n",
    "    model = model.parse(param)\n",
    "\n",
    "    model_ls = decode.utils.model_io.LoadSaveModel(model, output_file=model_out)\n",
    "\n",
    "    model = model_ls.load_init()\n",
    "    model = model.to(torch.device(device))\n",
    "\n",
    "    # Small collection of optimisers\n",
    "    optimizer_available = {\n",
    "        'Adam': torch.optim.Adam,\n",
    "        'AdamW': torch.optim.AdamW\n",
    "    }\n",
    "\n",
    "    optimizer = optimizer_available[param.HyperParameter.optimizer]\n",
    "    optimizer = optimizer(model.parameters(), **param.HyperParameter.opt_param)\n",
    "\n",
    "    \"\"\"Loss function.\"\"\"\n",
    "    criterion = decode.neuralfitter.loss.GaussianMMLoss(\n",
    "        xextent=param.Simulation.psf_extent[0],\n",
    "        yextent=param.Simulation.psf_extent[1],\n",
    "        img_shape=param.Simulation.img_size,\n",
    "        device=device,\n",
    "        chweight_stat=param.HyperParameter.chweight_stat)\n",
    "\n",
    "    \"\"\"Learning Rate and Simulation Scheduling\"\"\"\n",
    "    lr_scheduler_available = {\n",
    "        'ReduceLROnPlateau': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        'StepLR': torch.optim.lr_scheduler.StepLR\n",
    "    }\n",
    "    lr_scheduler = lr_scheduler_available[param.HyperParameter.learning_rate_scheduler]\n",
    "    lr_scheduler = lr_scheduler(optimizer, **param.HyperParameter.learning_rate_scheduler_param)\n",
    "\n",
    "    \"\"\"Checkpointing\"\"\"\n",
    "    checkpoint = CheckPoint(path=ckpt_path)\n",
    "\n",
    "    \"\"\"Setup gradient modification\"\"\"\n",
    "    grad_mod = param.HyperParameter.grad_mod\n",
    "\n",
    "    \"\"\"Log the model (Graph) \"\"\"\n",
    "    try:\n",
    "        dummy = torch.rand((2, param.HyperParameter.channels_in,\n",
    "                            *param.Simulation.img_size), requires_grad=False).to(torch.device(device))\n",
    "        logger.add_graph(model, dummy)\n",
    "\n",
    "    except:\n",
    "        print(\"Did not log graph.\")\n",
    "        # raise RuntimeError(\"Your dummy input is wrong. Please update it.\")\n",
    "\n",
    "    \"\"\"Setup Target generator consisting possibly multiple steps in a transformation sequence.\"\"\"\n",
    "    tar_proc = decode.neuralfitter.utils.processing.TransformSequence(\n",
    "        [\n",
    "            # param_tar --> phot/max, z/z_max, bg/bg_max\n",
    "            decode.neuralfitter.scale_transform.ParameterListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max)\n",
    "        ])\n",
    "\n",
    "    train_IDs = numpy.arange(1,9001,1).tolist()\n",
    "    val_IDs = numpy.arange(9001,10001,1).tolist()\n",
    "    # train_IDs = numpy.arange(0,9000,1).tolist()\n",
    "    # val_IDs = numpy.arange(9000,10000,1).tolist()\n",
    "\n",
    "    train_ds = decode.neuralfitter.dataset.rPSFDataset(root_dir=param.InOut.data_path,\n",
    "                                                       list_IDs=train_IDs, label_path=None, \n",
    "                                                       n_max=param.HyperParameter.max_number_targets,\n",
    "                                                       tar_proc=tar_proc,\n",
    "                                                       img_shape=param.Simulation.img_size)\n",
    "\n",
    "    test_ds = decode.neuralfitter.dataset.rPSFDataset(root_dir=param.InOut.data_path,\n",
    "                                                       list_IDs=val_IDs, label_path=None, \n",
    "                                                       n_max=param.HyperParameter.max_number_targets,\n",
    "                                                       tar_proc=tar_proc,\n",
    "                                                       img_shape=param.Simulation.img_size)\n",
    "    \n",
    "    # print(test_ds.label_gen())\n",
    "\n",
    "    \"\"\"Set up post processor\"\"\"\n",
    "    if param.PostProcessing is None:\n",
    "        post_processor = decode.neuralfitter.post_processing.NoPostProcessing(xy_unit='px',\n",
    "                                                                              px_size=param.Camera.px_size)\n",
    "\n",
    "    elif param.PostProcessing == 'LookUp':\n",
    "        post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "\n",
    "            decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max),\n",
    "\n",
    "            decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "            decode.neuralfitter.post_processing.LookUpPostProcessing(\n",
    "                raw_th=param.PostProcessingParam.raw_th,\n",
    "                pphotxyzbg_mapping=[0, 1, 2, 3, 4, -1],\n",
    "                xy_unit='px',\n",
    "                px_size=param.Camera.px_size)\n",
    "        ])\n",
    "\n",
    "    elif param.PostProcessing in ('SpatialIntegration', 'NMS'):  # NMS as legacy support\n",
    "        post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "            # out_tar --> out_tar: photo*photo_max, z*z_max, bg*bg_max\n",
    "            decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max),\n",
    "            # offset --> coordinate e.g., 0.2 --> 10.2 \n",
    "            decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "            decode.neuralfitter.post_processing.SpatialIntegration(\n",
    "                raw_th=param.PostProcessingParam.raw_th, # 0.5\n",
    "                xy_unit='px')\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \"\"\"Evaluation Specification\"\"\"\n",
    "    matcher = decode.evaluation.match_emittersets.GreedyHungarianMatching.parse(param)\n",
    "    # matcher = None\n",
    "\n",
    "    return train_ds, test_ds, model, model_ls, optimizer, criterion, lr_scheduler, grad_mod, post_processor, matcher, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dataloader(param, train_ds, test_ds=None):\n",
    "    \"\"\"Set up dataloader\"\"\"\n",
    "\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        dataset=train_ds,\n",
    "        batch_size=param.HyperParameter.batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        num_workers=param.Hardware.num_worker_train,\n",
    "        pin_memory=True,\n",
    "        collate_fn=decode.neuralfitter.utils.dataloader_customs.smlm_collate)\n",
    "\n",
    "    if test_ds is not None:\n",
    "\n",
    "        test_dl = torch.utils.data.DataLoader(\n",
    "            dataset=test_ds,\n",
    "            batch_size=param.HyperParameter.batch_size,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            num_workers=param.Hardware.num_worker_train,\n",
    "            pin_memory=False,\n",
    "            collate_fn=decode.neuralfitter.utils.dataloader_customs.smlm_collate)\n",
    "    else:\n",
    "\n",
    "        test_dl = None\n",
    "\n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "args.device='cuda:2' \n",
    "args.param_file='/home/lingjia/Documents/rPSF/NN/param_v2.yaml'\n",
    "args.data_path_override='/media/hdd/rPSF/data/decode/decode_impl_train'\n",
    "args.img_size_override=96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load Parameters and back them up to the network output directory\"\"\"\n",
    "param_file = Path(args.param_file)\n",
    "param = decode.utils.param_io.ParamHandling().load_params(param_file)\n",
    "\n",
    "# add meta information - Meta=namespace(version='0.10.0'),\n",
    "param.Meta.version = decode.utils.bookkeeping.decode_state()\n",
    "# print(param)\n",
    "print(param.InOut.checkpoint_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated.\n",
      "Model initialised as specified in the constructor.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Experiment ID\"\"\"\n",
    "if param.InOut.checkpoint_init is None:\n",
    "    experiment_id = datetime.datetime.now().strftime(\n",
    "        \"%Y-%m-%d_%H-%M-%S\") + '_' + socket.gethostname()\n",
    "    from_ckpt = False\n",
    "    if args.log_comment:\n",
    "        experiment_id = experiment_id + '_' + args.log_comment\n",
    "else:\n",
    "    from_ckpt = True\n",
    "    experiment_id = Path(param.InOut.checkpoint_init).parent.name\n",
    "\n",
    "\"\"\"Set up unique folder for experiment\"\"\"\n",
    "if not from_ckpt:\n",
    "    experiment_path = Path(param.InOut.experiment_out) / Path(experiment_id)\n",
    "else:\n",
    "    experiment_path = Path(param.InOut.checkpoint_init).parent\n",
    "\n",
    "if not experiment_path.parent.exists():\n",
    "    experiment_path.parent.mkdir()\n",
    "\n",
    "if not from_ckpt:\n",
    "    experiment_path.mkdir(exist_ok=False)\n",
    "\n",
    "model_out = experiment_path / Path('model.pt')\n",
    "ckpt_path = experiment_path / Path('ckpt.pt')\n",
    "\n",
    "# Modify parameters\n",
    "if args.num_worker_override is not None:\n",
    "    param.Hardware.num_worker_train = args.num_worker_override\n",
    "\n",
    "\"\"\"Hardware / Server stuff.\"\"\"\n",
    "if args.device is not None:\n",
    "    device = args.device\n",
    "    # param.Hardware.device_simulation = device_overwrite  # lazy assumption\n",
    "else:\n",
    "    device = param.Hardware.device\n",
    "\n",
    "if args.data_path_override is not None:\n",
    "    param.InOut.data_path = args.data_path_override\n",
    "\n",
    "if args.img_size_override is not None:\n",
    "    param.Simulation.img_size = [args.img_size_override,args.img_size_override]\n",
    "    param.Simulation.psf_extent = [[-0.5, args.img_size_override-0.5],\n",
    "                                    [-0.5, args.img_size_override-0.5], None]\n",
    "\n",
    "    param.TestSet.frame_extent = param.Simulation.psf_extent\n",
    "    param.TestSet.img_size = param.Simulation.img_size\n",
    "\n",
    "# Backup the parameter file under the network output path with the experiments ID\n",
    "param_backup_in = experiment_path / Path('param_run_in').with_suffix(param_file.suffix)\n",
    "shutil.copy(param_file, param_backup_in)\n",
    "\n",
    "param_backup = experiment_path / Path('param_run').with_suffix(param_file.suffix)\n",
    "decode.utils.param_io.ParamHandling().write_params(param_backup, param)\n",
    "\n",
    "if sys.platform in ('linux', 'darwin'):\n",
    "    os.nice(param.Hardware.unix_niceness)\n",
    "elif param.Hardware.unix_niceness is not None:\n",
    "    print(f\"Cannot set niceness on platform {sys.platform}. You probably do not need to worry.\")\n",
    "\n",
    "torch.set_num_threads(param.Hardware.torch_threads)\n",
    "\n",
    "\"\"\"Setup Log System\"\"\"\n",
    "if args.no_log:\n",
    "    logger = decode.neuralfitter.utils.logger.NoLog()\n",
    "\n",
    "else:\n",
    "    log_folder = experiment_path\n",
    "\n",
    "    logger = decode.neuralfitter.utils.logger.MultiLogger(\n",
    "        [decode.neuralfitter.utils.logger.SummaryWriter(log_dir=log_folder,\n",
    "                                                        filter_keys=[\"dx_red_mu\", \"dx_red_sig\",\n",
    "                                                                        \"dy_red_mu\",\n",
    "                                                                        \"dy_red_sig\", \"dz_red_mu\",\n",
    "                                                                        \"dz_red_sig\",\n",
    "                                                                        \"dphot_red_mu\",\n",
    "                                                                        \"dphot_red_sig\"]),\n",
    "            decode.neuralfitter.utils.logger.DictLogger()])\n",
    "\n",
    "# sim_train, sim_test = setup_random_simulation(param)\n",
    "ds_train, ds_test, model, model_ls, optimizer, criterion, lr_scheduler, grad_mod, post_processor, matcher, ckpt = setup_trainer(logger, model_out, ckpt_path, device, param)\n",
    "dl_train, dl_test = setup_dataloader(param, ds_train, ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if from_ckpt:\n",
    "    ckpt = decode.utils.checkpoint.CheckPoint.load(param.InOut.checkpoint_init)\n",
    "    model.load_state_dict(ckpt.model_state)\n",
    "    optimizer.load_state_dict(ckpt.optimizer_state)\n",
    "    lr_scheduler.load_state_dict(ckpt.lr_sched_state)\n",
    "    first_epoch = ckpt.step + 1\n",
    "    model = model.train()\n",
    "    print(f'Resuming training from checkpoint {experiment_id} Epoch {first_epoch}')\n",
    "\n",
    "else:\n",
    "    first_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 Test time:5.1: 100%|██████████████████████████| 32/32 [00:05<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:8.67e+06\n",
      "log time:24.002115488052368\n",
      "Epoch1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/281 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 450.00 MiB (GPU 2; 10.76 GiB total capacity; 3.16 GiB already allocated; 277.44 MiB free; 3.68 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=8'>9</a>\u001b[0m     _ \u001b[39m=\u001b[39m decode\u001b[39m.\u001b[39;49mneuralfitter\u001b[39m.\u001b[39;49mtrain_val_impl\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=9'>10</a>\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=10'>11</a>\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=11'>12</a>\u001b[0m         loss\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=12'>13</a>\u001b[0m         dataloader\u001b[39m=\u001b[39;49mdl_train,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=13'>14</a>\u001b[0m         grad_rescale\u001b[39m=\u001b[39;49mparam\u001b[39m.\u001b[39;49mHyperParameter\u001b[39m.\u001b[39;49mmoeller_gradient_rescale,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=14'>15</a>\u001b[0m         grad_mod\u001b[39m=\u001b[39;49mgrad_mod,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=15'>16</a>\u001b[0m         epoch\u001b[39m=\u001b[39;49mi,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=16'>17</a>\u001b[0m         device\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(device),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=17'>18</a>\u001b[0m         logger\u001b[39m=\u001b[39;49mlogger\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=18'>19</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=20'>21</a>\u001b[0m \u001b[39m# val_loss=avg of loss for all batches\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=21'>22</a>\u001b[0m \u001b[39m# test_out=list of network_output: [\"loss\", \"x\", \"y_out\", \"y_tar\", \"weight\", \"em_tar\"]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=22'>23</a>\u001b[0m val_loss, test_out \u001b[39m=\u001b[39m decode\u001b[39m.\u001b[39mneuralfitter\u001b[39m.\u001b[39mtrain_val_impl\u001b[39m.\u001b[39mtest(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=23'>24</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=24'>25</a>\u001b[0m     loss\u001b[39m=\u001b[39mcriterion,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=25'>26</a>\u001b[0m     dataloader\u001b[39m=\u001b[39mdl_test,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=26'>27</a>\u001b[0m     epoch\u001b[39m=\u001b[39mi,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000008vscode-remote?line=27'>28</a>\u001b[0m     device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(device))\n",
      "File \u001b[0;32m~/Documents/rPSF/NN/decode/neuralfitter/train_val_impl.py:43\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss, dataloader, grad_rescale, grad_mod, epoch, device, logger)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lingjia/Documents/rPSF/NN/decode/neuralfitter/train_val_impl.py?line=39'>40</a>\u001b[0m     loss_val \u001b[39m=\u001b[39m loss_val \u001b[39m*\u001b[39m weight\n\u001b[1;32m     <a href='file:///home/lingjia/Documents/rPSF/NN/decode/neuralfitter/train_val_impl.py?line=41'>42</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='file:///home/lingjia/Documents/rPSF/NN/decode/neuralfitter/train_val_impl.py?line=42'>43</a>\u001b[0m loss_val\u001b[39m.\u001b[39;49mmean()\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='file:///home/lingjia/Documents/rPSF/NN/decode/neuralfitter/train_val_impl.py?line=44'>45</a>\u001b[0m \u001b[39m\"\"\"Gradient Modification\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/lingjia/Documents/rPSF/NN/decode/neuralfitter/train_val_impl.py?line=45'>46</a>\u001b[0m \u001b[39mif\u001b[39;00m grad_mod:\n",
      "File \u001b[0;32m~/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py:221\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=212'>213</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m Tensor \u001b[39mand\u001b[39;00m has_torch_function(relevant_args):\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=213'>214</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=214'>215</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=215'>216</a>\u001b[0m         relevant_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=218'>219</a>\u001b[0m         retain_graph\u001b[39m=\u001b[39mretain_graph,\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=219'>220</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph)\n\u001b[0;32m--> <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=220'>221</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/autograd/__init__.py:130\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=126'>127</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=127'>128</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=129'>130</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=130'>131</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph,\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=131'>132</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 450.00 MiB (GPU 2; 10.76 GiB total capacity; 3.16 GiB already allocated; 277.44 MiB free; 3.68 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "param.HyperParameter.epochs = 2\n",
    "best_val_loss = inf\n",
    "for i in range(first_epoch, param.HyperParameter.epochs):\n",
    "    logger.add_scalar('learning/learning_rate', optimizer.param_groups[0]['lr'], i)\n",
    "\n",
    "    print(f'Epoch{i}')\n",
    "\n",
    "    if i >= 1:\n",
    "        _ = decode.neuralfitter.train_val_impl.train(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            loss=criterion,\n",
    "            dataloader=dl_train,\n",
    "            grad_rescale=param.HyperParameter.moeller_gradient_rescale,\n",
    "            grad_mod=grad_mod,\n",
    "            epoch=i,\n",
    "            device=torch.device(device),\n",
    "            logger=logger\n",
    "        )\n",
    "\n",
    "    # val_loss=avg of loss for all batches\n",
    "    # test_out=list of network_output: [\"loss\", \"x\", \"y_out\", \"y_tar\", \"weight\", \"em_tar\"]\n",
    "    val_loss, test_out = decode.neuralfitter.train_val_impl.test(\n",
    "        model=model,\n",
    "        loss=criterion,\n",
    "        dataloader=dl_test,\n",
    "        epoch=i,\n",
    "        device=torch.device(device))\n",
    "    # print(val_loss)\n",
    "\n",
    "    if best_val_loss - val_loss >1e-4:\n",
    "        best_val_loss = val_loss\n",
    "        # model_ls.save(model, None, epoch_idx='best')\n",
    "\n",
    "    t0 = time.time()\n",
    "    if i%3 == 0:\n",
    "        \"\"\"Post-Process and Evaluate\"\"\"\n",
    "        log_train_val_progress.post_process_log_test(loss_cmp=test_out.loss,\n",
    "                                                    loss_scalar=val_loss,\n",
    "                                                    x=test_out.x, y_out=test_out.y_out,\n",
    "                                                    y_tar=test_out.y_tar,\n",
    "                                                    weight=test_out.weight,\n",
    "                                                    em_tar=ds_test.emitter(),\n",
    "                                                    px_border=-0.5, px_size=1.,\n",
    "                                                    post_processor=post_processor,\n",
    "                                                    matcher=matcher, logger=logger,\n",
    "                                                    step=i)\n",
    "    else:\n",
    "        log_train_val_progress.log_kpi_simplified(loss_scalar=val_loss,\n",
    "                                                loss_cmp=test_out.loss,\n",
    "                                                logger=logger,\n",
    "                                                step=i)\n",
    "\n",
    "    t_log = time.time() - t0\n",
    "    print(f'log time:{t_log}')\n",
    "\n",
    "    if i >= 1:\n",
    "        if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            lr_scheduler.step(val_loss)\n",
    "        else:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "\n",
    "print(\"Training finished after reaching maximum number of epochs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = inf\n",
    "i = first_epoch\n",
    "logger.add_scalar('learning/learning_rate', optimizer.param_groups[0]['lr'], i)\n",
    "print(f'Epoch {first_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/281 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 450.00 MiB (GPU 2; 10.76 GiB total capacity; 3.16 GiB already allocated; 305.44 MiB free; 3.65 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000010vscode-remote?line=0'>1</a>\u001b[0m i \u001b[39m=\u001b[39m first_epoch\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000010vscode-remote?line=1'>2</a>\u001b[0m _ \u001b[39m=\u001b[39m decode\u001b[39m.\u001b[39;49mneuralfitter\u001b[39m.\u001b[39;49mtrain_val_impl\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000010vscode-remote?line=2'>3</a>\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000010vscode-remote?line=3'>4</a>\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000010vscode-remote?line=4'>5</a>\u001b[0m         loss\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000010vscode-remote?line=5'>6</a>\u001b[0m         dataloader\u001b[39m=\u001b[39;49mdl_train,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000010vscode-remote?line=6'>7</a>\u001b[0m         grad_rescale\u001b[39m=\u001b[39;49mparam\u001b[39m.\u001b[39;49mHyperParameter\u001b[39m.\u001b[39;49mmoeller_gradient_rescale,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000010vscode-remote?line=7'>8</a>\u001b[0m         grad_mod\u001b[39m=\u001b[39;49mgrad_mod,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000010vscode-remote?line=8'>9</a>\u001b[0m         epoch\u001b[39m=\u001b[39;49mi,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000010vscode-remote?line=9'>10</a>\u001b[0m         device\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(device),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000010vscode-remote?line=10'>11</a>\u001b[0m         logger\u001b[39m=\u001b[39;49mlogger\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_tmp.ipynb#ch0000010vscode-remote?line=11'>12</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/rPSF/NN/decode/neuralfitter/train_val_impl.py:43\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss, dataloader, grad_rescale, grad_mod, epoch, device, logger)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lingjia/Documents/rPSF/NN/decode/neuralfitter/train_val_impl.py?line=39'>40</a>\u001b[0m     loss_val \u001b[39m=\u001b[39m loss_val \u001b[39m*\u001b[39m weight\n\u001b[1;32m     <a href='file:///home/lingjia/Documents/rPSF/NN/decode/neuralfitter/train_val_impl.py?line=41'>42</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='file:///home/lingjia/Documents/rPSF/NN/decode/neuralfitter/train_val_impl.py?line=42'>43</a>\u001b[0m loss_val\u001b[39m.\u001b[39;49mmean()\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='file:///home/lingjia/Documents/rPSF/NN/decode/neuralfitter/train_val_impl.py?line=44'>45</a>\u001b[0m \u001b[39m\"\"\"Gradient Modification\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/lingjia/Documents/rPSF/NN/decode/neuralfitter/train_val_impl.py?line=45'>46</a>\u001b[0m \u001b[39mif\u001b[39;00m grad_mod:\n",
      "File \u001b[0;32m~/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py:221\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=212'>213</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m Tensor \u001b[39mand\u001b[39;00m has_torch_function(relevant_args):\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=213'>214</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=214'>215</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=215'>216</a>\u001b[0m         relevant_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=218'>219</a>\u001b[0m         retain_graph\u001b[39m=\u001b[39mretain_graph,\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=219'>220</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph)\n\u001b[0;32m--> <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/tensor.py?line=220'>221</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/autograd/__init__.py:130\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=126'>127</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=127'>128</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=129'>130</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=130'>131</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph,\n\u001b[1;32m    <a href='file:///home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/autograd/__init__.py?line=131'>132</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 450.00 MiB (GPU 2; 10.76 GiB total capacity; 3.16 GiB already allocated; 305.44 MiB free; 3.65 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "i = first_epoch\n",
    "_ = decode.neuralfitter.train_val_impl.train(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss=criterion,\n",
    "        dataloader=dl_train,\n",
    "        grad_rescale=param.HyperParameter.moeller_gradient_rescale,\n",
    "        grad_mod=grad_mod,\n",
    "        epoch=i,\n",
    "        device=torch.device(device),\n",
    "        logger=logger\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "310 Test time:2.9: 100%|████████████████████████| 32/32 [00:02<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:29.7\n"
     ]
    }
   ],
   "source": [
    "# val_loss=avg of loss for all batches\n",
    "# test_out=list of network_output: [\"loss\", \"x\", \"y_out\", \"y_tar\", \"weight\", \"em_tar\"]\n",
    "val_loss, test_out = decode.neuralfitter.train_val_impl.test(\n",
    "    model=model,\n",
    "    loss=criterion,\n",
    "    dataloader=dl_test,\n",
    "    epoch=i,\n",
    "    device=torch.device(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Post-Process and Evaluate\"\"\"\n",
    "log_train_val_progress.post_process_log_test(loss_cmp=test_out.loss,\n",
    "                                            loss_scalar=val_loss,\n",
    "                                            x=test_out.x, y_out=test_out.y_out,\n",
    "                                            y_tar=test_out.y_tar,\n",
    "                                            weight=test_out.weight,\n",
    "                                            em_tar=ds_test.emitter(),\n",
    "                                            px_border=-0.5, px_size=1.,\n",
    "                                            post_processor=post_processor,\n",
    "                                            matcher=matcher, logger=logger,\n",
    "                                            step=i)\n",
    "\n",
    "if i >= 1:\n",
    "    if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "        lr_scheduler.step(val_loss)\n",
    "    else:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "model_ls.save(model, None)\n",
    "if args.no_log:\n",
    "    ckpt.dump(model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict(),\n",
    "                step=i)\n",
    "else:\n",
    "    ckpt.dump(model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict(),\n",
    "                log=logger.logger[1].log_dict, step=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[68.4191, 75.5939, 15.6891],\n",
      "        [23.6483, 22.6351, 26.2191],\n",
      "        [42.6798, 76.1096,  6.8475]])\n",
      "tensor([113.5610, 105.1080, 139.0421])\n"
     ]
    }
   ],
   "source": [
    "print(ds_train.emitter().xyz[:3,:])\n",
    "# print(ds_train.emitter().frame_ix.shape)\n",
    "print(ds_train.emitter().phot[:3])\n",
    "# print(ds_train.emitter().bg.shape)\n",
    "# print(ds_train.emitter().get_subset_frame(1,1))\n",
    "# print(ds_train.emitter().frame_ix)\n",
    "\n",
    "# label_raw,path = ds_train.label_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[ 4.3076e-01,  5.1470e+01,  2.8865e+01,  6.1369e-01],\n",
    "        [ 5.9341e-01,  5.4971e+01,  1.6139e+01,  1.0704e+00],\n",
    "        [ 6.4862e-01,  4.3625e+01,  5.1123e+01, -1.0026e+00],\n",
    "        [ 5.3842e-01,  4.6118e+01,  2.4503e+01, -1.3809e+00],\n",
    "        [ 5.8623e-01,  7.2888e+01,  2.6713e+01,  1.6181e+00],\n",
    "        [ 4.4575e-01,  5.0563e+01,  4.2720e+01, -5.3808e-01],\n",
    "        [ 7.2379e-01,  4.6952e+01,  5.5178e+01,  3.2167e-01],\n",
    "        [ 7.1583e-01,  3.6665e+01,  4.7480e+01, -2.1770e-02],\n",
    "        [ 6.1125e-01,  5.3613e+01,  5.7800e+01,  1.2984e+00],\n",
    "        [ 6.1650e-01,  6.0197e+01,  7.6087e+01,  1.2360e-02],\n",
    "        [ 5.2857e-01,  5.1036e+01,  6.6435e+01,  6.8342e-01],\n",
    "        [ 6.2562e-01,  7.6063e+01,  3.3609e+01, -2.1582e-01],\n",
    "        [ 4.0985e-01,  6.7193e+01,  4.2250e+01, -1.7986e+00],\n",
    "        [ 4.5632e-01,  6.2332e+01,  3.6541e+01,  1.1406e+00],\n",
    "        [ 4.4718e-01,  2.0260e+01,  3.8910e+01,  1.9087e+00],\n",
    "        [ 7.1011e-01,  7.8753e+01,  3.5229e+01, -1.4820e+00],\n",
    "        [ 6.5208e-01,  2.9200e+01,  5.3470e+01, -1.8987e+00],\n",
    "        [ 6.7736e-01,  1.8492e+01,  2.1681e+01,  4.5164e-01],\n",
    "        [ 4.0185e-01,  1.8372e+01,  3.6160e+01, -1.8527e+00],\n",
    "        [ 5.4529e-01,  4.7004e+01,  7.1986e+01,  1.5167e+00],\n",
    "        [ 4.0989e-01,  1.5032e+01,  2.5290e+01,  1.6821e+00],\n",
    "        [ 4.8636e-01,  5.7208e+01,  4.6808e+01,  1.2659e+00],\n",
    "        [ 5.4032e-01,  5.0307e+01,  2.9100e+01,  8.7874e-01],\n",
    "        [ 6.2395e-01,  5.0439e+01,  2.7731e+01,  2.4122e-01],\n",
    "        [ 5.5494e-01,  5.0901e+01,  2.9253e+01,  2.4678e-01],\n",
    "        [ 6.2285e-01,  5.1220e+01,  2.9807e+01,  2.5108e-01],\n",
    "        [ 5.7925e-01,  4.9501e+01,  2.8861e+01,  4.6229e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([204818, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.1356e+02,  2.0419e+01,  2.7594e+01, -4.3109e+00],\n",
       "        [ 0.0000e+00,  1.0511e+02, -2.4352e+01, -2.5365e+01,  6.2191e+00],\n",
       "        [ 0.0000e+00,  1.3904e+02, -5.3202e+00,  2.8110e+01, -1.3153e+01],\n",
       "        ...,\n",
       "        [ 9.9990e+03,  1.1099e+02,  2.9010e+00, -1.8747e+01,  2.4678e+00],\n",
       "        [ 9.9990e+03,  1.2457e+02,  3.2202e+00, -1.8193e+01,  2.5108e+00],\n",
       "        [ 9.9990e+03,  1.1585e+02,  1.5008e+00, -1.9139e+01,  4.6229e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.label_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = 'im1.mat'\n",
    "aa.strip('im').strip('.mat')\n",
    "\n",
    "    # param_path = Path(param.InOut.checkpoint_init).parent/ Path('param_run').with_suffix(param_file.suffix)\n",
    "    # param = decode.utils.param_io.load_params(param_path)\n",
    "\n",
    "    # model = decode.neuralfitter.models.SigmaMUNet.parse(param)\n",
    "    # model = decode.utils.model_io.LoadSaveModel(\n",
    "    #     model, input_file=param.InOut.checkpoint_init, output_file=None).load_init(device)\n",
    "    # model.to('cuda:3')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32d9234fb3a060fbd30877034f28c0fca724fa3d0d25a605ad46b1806c555f07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('decode_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
