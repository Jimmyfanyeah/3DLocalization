{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse, datetime, numpy, os, shutil, sys, time\n",
    "from cmath import inf\n",
    "import socket\n",
    "from pathlib import Path\n",
    "import torch\n",
    "# self-defined modules\n",
    "import decode.evaluation\n",
    "import decode.neuralfitter\n",
    "import decode.neuralfitter.coord_transform\n",
    "import decode.neuralfitter.utils\n",
    "import decode.simulation\n",
    "import decode.utils\n",
    "# from decode.neuralfitter.train.random_simulation import setup_random_simulation\n",
    "from decode.neuralfitter.utils import log_train_val_progress\n",
    "from decode.utils.checkpoint import CheckPoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Training Args')\n",
    "\n",
    "    parser.add_argument('-i', '--device', default=None, \n",
    "                        help='Specify the device string (cpu, cuda, cuda:0) and overwrite param.',\n",
    "                        type=str)\n",
    "\n",
    "    parser.add_argument('-p', '--param_file', default=None,\n",
    "                        help='Specify your parameter file (.yml or .json).', type=str)\n",
    "\n",
    "    parser.add_argument('-w', '--num_worker_override',default=None,\n",
    "                        help='Override the number of workers for the dataloaders.',\n",
    "                        type=int)\n",
    "\n",
    "    parser.add_argument('-n', '--no_log', default=False, action='store_true',\n",
    "                        help='Set no log if you do not want to log the current run.')\n",
    "\n",
    "    parser.add_argument('-c', '--log_comment', default=None,\n",
    "                        help='Add a log_comment to the run.')\n",
    "\n",
    "    parser.add_argument('-d', '--data_path_override', default=None,\n",
    "                        help='Specify your path to data', type=str)\n",
    "\n",
    "    parser.add_argument('-is', '--img_size_override', default=None,\n",
    "                        help='Override img size', type=int)\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "args.device = 'cuda'\n",
    "args.param_file ='/home/lingjia/Documents/rpsf/NN/param.yaml'\n",
    "args.data_path_override = '/media/hdd_4T/lingjia/rPSF/20220716_decode_variant_v2/data_train/30k_pt50L5'\n",
    "args.img_size_override = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_trainer(logger, model_out, ckpt_path, device, param):\n",
    "    \"\"\"Set model, optimiser, loss and schedulers\"\"\"\n",
    "    models_available = {\n",
    "        'SigmaMUNet': decode.neuralfitter.models.SigmaMUNet_variant,\n",
    "        'DoubleMUnet': decode.neuralfitter.models.model_param.DoubleMUnet,\n",
    "        'SimpleSMLMNet': decode.neuralfitter.models.model_param.SimpleSMLMNet,\n",
    "    }\n",
    "\n",
    "    model = models_available[param.HyperParameter.architecture]\n",
    "    model = model.parse(param)\n",
    "\n",
    "    model_ls = decode.utils.model_io.LoadSaveModel(model, output_file=model_out)\n",
    "\n",
    "    model = model_ls.load_init()\n",
    "    model = model.to(torch.device(device))\n",
    "\n",
    "    # Small collection of optimisers\n",
    "    optimizer_available = {\n",
    "        'Adam': torch.optim.Adam,\n",
    "        'AdamW': torch.optim.AdamW,\n",
    "        'SGD': torch.optim.SGD\n",
    "    }\n",
    "\n",
    "    optimizer = optimizer_available[param.HyperParameter.optimizer]\n",
    "    optimizer = optimizer(model.parameters(), **param.HyperParameter.opt_param)\n",
    "\n",
    "    \"\"\"Loss function.\"\"\"\n",
    "    criterion = decode.neuralfitter.loss.GaussianMMLoss(\n",
    "        xextent=param.Simulation.psf_extent[0],\n",
    "        yextent=param.Simulation.psf_extent[1],\n",
    "        img_shape=param.Simulation.img_size,\n",
    "        device=device,\n",
    "        chweight_stat=param.HyperParameter.chweight_stat)\n",
    "\n",
    "    \"\"\"Learning Rate and Simulation Scheduling\"\"\"\n",
    "    lr_scheduler_available = {\n",
    "        'ReduceLROnPlateau': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        'StepLR': torch.optim.lr_scheduler.StepLR\n",
    "    }\n",
    "    lr_scheduler = lr_scheduler_available[param.HyperParameter.learning_rate_scheduler]\n",
    "    lr_scheduler = lr_scheduler(optimizer, **param.HyperParameter.learning_rate_scheduler_param)\n",
    "\n",
    "    \"\"\"Checkpointing\"\"\"\n",
    "    checkpoint = CheckPoint(path=ckpt_path)\n",
    "\n",
    "    \"\"\"Setup gradient modification\"\"\"\n",
    "    grad_mod = param.HyperParameter.grad_mod\n",
    "\n",
    "    \"\"\"Log the model (Graph) \"\"\"\n",
    "    try:\n",
    "        dummy = torch.rand((2, param.HyperParameter.channels_in,\n",
    "                            *param.Simulation.img_size), requires_grad=False).to(torch.device(device))\n",
    "        logger.add_graph(model, dummy)\n",
    "\n",
    "    except:\n",
    "        print(\"Did not log graph.\")\n",
    "        # raise RuntimeError(\"Your dummy input is wrong. Please update it.\")\n",
    "\n",
    "    \"\"\"Setup Target generator consisting possibly multiple steps in a transformation sequence.\"\"\"\n",
    "    tar_proc = decode.neuralfitter.utils.processing.TransformSequence(\n",
    "        [\n",
    "            # param_tar --> phot/max, z/z_max, bg/bg_max\n",
    "            decode.neuralfitter.scale_transform.ParameterListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max)\n",
    "        ])\n",
    "\n",
    "    # Split train & val set\n",
    "    train_IDs = numpy.arange(1,101,1).tolist()\n",
    "    val_IDs = numpy.arange(101,111,1).tolist()\n",
    "\n",
    "    train_ds = decode.neuralfitter.dataset.rPSFDataset(root_dir=param.InOut.data_path,\n",
    "                                                       list_IDs=train_IDs, label_path=None, \n",
    "                                                       n_max=param.HyperParameter.max_number_targets,\n",
    "                                                       tar_proc=tar_proc,\n",
    "                                                       img_shape=param.Simulation.img_size)\n",
    "\n",
    "    test_ds = decode.neuralfitter.dataset.rPSFDataset(root_dir=param.InOut.data_path,\n",
    "                                                       list_IDs=val_IDs, label_path=None, \n",
    "                                                       n_max=param.HyperParameter.max_number_targets,\n",
    "                                                       tar_proc=tar_proc,\n",
    "                                                       img_shape=param.Simulation.img_size)\n",
    "\n",
    "    # print(test_ds.label_gen())\n",
    "\n",
    "    \"\"\"Set up post processor\"\"\"\n",
    "    if param.PostProcessing is None:\n",
    "        post_processor = decode.neuralfitter.post_processing.NoPostProcessing(xy_unit='px',\n",
    "                                                                              px_size=param.Camera.px_size)\n",
    "\n",
    "    elif param.PostProcessing == 'LookUp':\n",
    "        post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "\n",
    "            decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max),\n",
    "\n",
    "            decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "            decode.neuralfitter.post_processing.LookUpPostProcessing(\n",
    "                raw_th=param.PostProcessingParam.raw_th,\n",
    "                pphotxyzbg_mapping=[0, 1, 2, 3, 4, -1],\n",
    "                xy_unit='px',\n",
    "                px_size=param.Camera.px_size)\n",
    "        ])\n",
    "\n",
    "    elif param.PostProcessing in ('SpatialIntegration', 'NMS'):  # NMS as legacy support\n",
    "        post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "            # out_tar --> out_tar: photo*photo_max, z*z_max, bg*bg_max\n",
    "            decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max),\n",
    "            # offset --> coordinate e.g., 0.2 --> 10.2 \n",
    "            decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "            decode.neuralfitter.post_processing.SpatialIntegration(\n",
    "                raw_th=param.PostProcessingParam.raw_th, # 0.5\n",
    "                xy_unit='px')\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \"\"\"Evaluation Specification\"\"\"\n",
    "    matcher = decode.evaluation.match_emittersets.GreedyHungarianMatching.parse(param)\n",
    "    # matcher = None\n",
    "\n",
    "    return train_ds, test_ds, model, model_ls, optimizer, criterion, lr_scheduler, grad_mod, post_processor, matcher, checkpoint\n",
    "\n",
    "\n",
    "def setup_dataloader(param, train_ds, test_ds=None):\n",
    "    \"\"\"Set up dataloader\"\"\"\n",
    "\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        dataset=train_ds,\n",
    "        batch_size=param.HyperParameter.batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        num_workers=param.Hardware.num_worker_train,\n",
    "        pin_memory=True,\n",
    "        collate_fn=decode.neuralfitter.utils.dataloader_customs.smlm_collate)\n",
    "\n",
    "    if test_ds is not None:\n",
    "\n",
    "        test_dl = torch.utils.data.DataLoader(\n",
    "            dataset=test_ds,\n",
    "            batch_size=param.HyperParameter.batch_size,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            num_workers=param.Hardware.num_worker_train,\n",
    "            pin_memory=False,\n",
    "            collate_fn=decode.neuralfitter.utils.dataloader_customs.smlm_collate)\n",
    "    else:\n",
    "\n",
    "        test_dl = None\n",
    "\n",
    "    return train_dl, test_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated.\n",
      "Model initialised as specified in the constructor.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"BEOFRE TRAIN MODEL - BEOFRE TUNE LOSS\"\"\"\n",
    "param_file = Path(args.param_file)\n",
    "param = decode.utils.param_io.ParamHandling().load_params(param_file)\n",
    "\n",
    "# add meta information - Meta=namespace(version='0.10.0'),\n",
    "param.Meta.version = decode.utils.bookkeeping.decode_state()\n",
    "\n",
    "\"\"\"Experiment ID\"\"\"\n",
    "if param.InOut.checkpoint_init is None:\n",
    "    experiment_id = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    from_ckpt = False\n",
    "    if args.log_comment:\n",
    "        experiment_id = experiment_id + '_' + args.log_comment\n",
    "else:\n",
    "    from_ckpt = True\n",
    "    experiment_id = Path(param.InOut.checkpoint_init).parent.name\n",
    "\n",
    "\"\"\"Set up unique folder for experiment\"\"\"\n",
    "if not from_ckpt:\n",
    "    experiment_path = Path(param.InOut.experiment_out) / Path(experiment_id)\n",
    "else:\n",
    "    experiment_path = Path(param.InOut.checkpoint_init).parent\n",
    "\n",
    "if not experiment_path.parent.exists():\n",
    "    experiment_path.parent.mkdir()\n",
    "\n",
    "if not from_ckpt:\n",
    "    experiment_path.mkdir(exist_ok=False)\n",
    "\n",
    "model_out = experiment_path / Path('model.pt')\n",
    "ckpt_path = experiment_path / Path('ckpt.pt')\n",
    "\n",
    "# Modify parameters\n",
    "if args.num_worker_override is not None:\n",
    "    param.Hardware.num_worker_train = args.num_worker_override\n",
    "\n",
    "\"\"\"Hardware / Server stuff.\"\"\"\n",
    "if args.device is not None:\n",
    "    device = args.device\n",
    "    # param.Hardware.device_simulation = device_overwrite  # lazy assumption\n",
    "else:\n",
    "    device = param.Hardware.device\n",
    "\n",
    "if args.data_path_override is not None:\n",
    "    param.InOut.data_path = args.data_path_override\n",
    "\n",
    "if args.img_size_override is not None:\n",
    "    param.Simulation.img_size = [args.img_size_override,args.img_size_override]\n",
    "    param.Simulation.psf_extent = [[-0.5, args.img_size_override-0.5],\n",
    "                                    [-0.5, args.img_size_override-0.5], None]\n",
    "\n",
    "    param.TestSet.frame_extent = param.Simulation.psf_extent\n",
    "    param.TestSet.img_size = param.Simulation.img_size\n",
    "\n",
    "# Backup the parameter file under the network output path with the experiments ID\n",
    "param_backup_in = experiment_path / Path('param_run_in').with_suffix(param_file.suffix)\n",
    "shutil.copy(param_file, param_backup_in)\n",
    "\n",
    "param_backup = experiment_path / Path('param_run').with_suffix(param_file.suffix)\n",
    "decode.utils.param_io.ParamHandling().write_params(param_backup, param)\n",
    "\n",
    "if sys.platform in ('linux', 'darwin'):\n",
    "    os.nice(param.Hardware.unix_niceness)\n",
    "elif param.Hardware.unix_niceness is not None:\n",
    "    print(f\"Cannot set niceness on platform {sys.platform}. You probably do not need to worry.\")\n",
    "\n",
    "torch.set_num_threads(param.Hardware.torch_threads)\n",
    "\n",
    "\"\"\"Setup Log System\"\"\"\n",
    "if args.no_log:\n",
    "    logger = decode.neuralfitter.utils.logger.NoLog()\n",
    "\n",
    "else:\n",
    "    log_folder = experiment_path\n",
    "\n",
    "    logger = decode.neuralfitter.utils.logger.MultiLogger(\n",
    "        [decode.neuralfitter.utils.logger.SummaryWriter(log_dir=log_folder,\n",
    "                                                        filter_keys=[\"dx_red_mu\", \"dx_red_sig\",\n",
    "                                                                        \"dy_red_mu\",\n",
    "                                                                        \"dy_red_sig\", \"dz_red_mu\",\n",
    "                                                                        \"dz_red_sig\",\n",
    "                                                                        \"dphot_red_mu\",\n",
    "                                                                        \"dphot_red_sig\"]),\n",
    "            decode.neuralfitter.utils.logger.DictLogger()])\n",
    "\n",
    "# sim_train, sim_test = setup_random_simulation(param)\n",
    "ds_train, ds_test, model, model_ls, optimizer, criterion, lr_scheduler, grad_mod, post_processor, matcher, ckpt = setup_trainer(logger, model_out, ckpt_path, device, param)\n",
    "\n",
    "dl_train, dl_test = setup_dataloader(param, ds_train, ds_test)\n",
    "\n",
    "if from_ckpt:\n",
    "    ckpt = decode.utils.checkpoint.CheckPoint.load(param.InOut.checkpoint_init)\n",
    "    model.load_state_dict(ckpt.model_state)\n",
    "    optimizer.load_state_dict(ckpt.optimizer_state)\n",
    "    lr_scheduler.load_state_dict(ckpt.lr_sched_state)\n",
    "    first_epoch = ckpt.step + 1\n",
    "    model = model.train()\n",
    "    print(f'Resuming training from checkpoint ' + experiment_id)\n",
    "else:\n",
    "    first_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SIMULATED INPUT X AND GROUND-TRUTH TARGET\"\"\"\n",
    "# INPUT\n",
    "x = torch.randn(1,1,4,4).to('cuda')\n",
    "# TARGET\n",
    "param_tar = torch.zeros(1,60,4)\n",
    "param_tar_v = torch.randn(2,4)\n",
    "param_tar[0,:2,:] = param_tar_v\n",
    "\n",
    "mask_tar = torch.zeros(1,60)\n",
    "mask_tar[0,:2] = 1\n",
    "\n",
    "bg = torch.ones((1,4,4))*5\n",
    "\n",
    "target = (param_tar.to('cuda'), mask_tar.to('cuda'), bg.to('cuda'))\n",
    "# WEIGHT\n",
    "weight = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_out: torch.Size([1, 19, 4, 4])\n",
      "bg loss: 277.627\n"
     ]
    }
   ],
   "source": [
    "\"\"\"OUTPUT OF SIMULATED INPUT X AND BASIC PROCESS AND BG LOSS\"\"\"\n",
    "output = model(x)\n",
    "print(f'y_out: {output.shape}')\n",
    "\n",
    "# SHAPE CHECK OF OUTPUT AND TARGET\n",
    "def _forward_checks(output: torch.Tensor, target: tuple, weight: None):\n",
    "    if weight is not None:\n",
    "        raise NotImplementedError(f\"Weight must be None for this loss implementation.\")\n",
    "\n",
    "    if output.dim() != 4:\n",
    "        raise ValueError(f\"Output must have 4 dimensions (N,C,H,W).\")\n",
    "\n",
    "    if output.size(1) != 19:\n",
    "        raise ValueError(f\"Wrong number of channels.\")\n",
    "\n",
    "    if len(target) != 3:\n",
    "        raise ValueError(f\"Wrong length of target.\")\n",
    "\n",
    "_forward_checks(output, target, weight)\n",
    "\n",
    "# FORMAT MODEL OUTPUT AND GROUND-TRUTH\n",
    "def _format_model_output(output: torch.Tensor) -> tuple:\n",
    "    \"\"\"\n",
    "    Transforms solely channel based model output into more meaningful variables.\n",
    "    Args:\n",
    "        output: model output\n",
    "    Returns:\n",
    "        tuple containing\n",
    "            p: N x 3 x H x W\n",
    "            pxyz_mu: N x 12 x H x W = 3phot, 3x, 3y, 3z\n",
    "            pxyz_sig: N x 12 x H x W = 3phot, 3x, 3y, 3z\n",
    "            bg: N x H x W\n",
    "    \"\"\"\n",
    "    p = output[:, 0:2] # 0,1\n",
    "    pxyz_mu = output[:, 2:10] # 2,3, 4,5, 6,7, 8,9\n",
    "    pxyz_sig = output[:, 10:-1] # 10,11, 12,13, 14,15, 16,17\n",
    "    bg = output[:, -1] # 27\n",
    "    return p, pxyz_mu, pxyz_sig, bg\n",
    "\n",
    "tar_param, tar_mask, tar_bg = target\n",
    "p, pxyz_mu, pxyz_sig, bg = _format_model_output(output)\n",
    "# print(bg.shape,tar_bg.shape)\n",
    "\n",
    "# BG LOSS\n",
    "_bg_loss = torch.nn.MSELoss(reduction='none')\n",
    "bg_loss = _bg_loss(bg, tar_bg).sum(-1).sum(-1)\n",
    "print(f'bg loss: {bg_loss.item():.3f}')\n",
    "# gmm_loss = _compute_gmm_loss(p, pxyz_mu, pxyz_sig, tar_param, tar_mask)\n",
    "# torch.set_printoptions(precision=4,sci_mode=False)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pxyz_mu shape: [1 8 4 4]\n",
      "p shape: torch.Size([1, 2, 4, 4]) mean: 0.1208 var: 0.1197\n",
      "log_prob version 1: -29.212\n"
     ]
    }
   ],
   "source": [
    "\"\"\"GMM LOSS - PROBABILITY LOSS\"\"\"\n",
    "# LOAD MODULES\n",
    "from abc import ABC, abstractmethod  # abstract class\n",
    "from typing import Union, Tuple\n",
    "import torch\n",
    "from deprecated import deprecated\n",
    "from torch import distributions\n",
    "import decode.generic.utils\n",
    "\n",
    "# gmm_loss = _compute_gmm_loss(p, pxyz_mu, pxyz_sig, tar_param, tar_mask)\n",
    "p, pxyz_mu, pxyz_sig, pxyz_tar, mask = p, pxyz_mu, pxyz_sig, tar_param, tar_mask\n",
    "\n",
    "# FUNCTION - COMPUTE_GMM_LOSS\n",
    "\"\"\"\n",
    "Computes the Gaussian Mixture Loss.\n",
    "Args:\n",
    "    p: the model's detection prediction (sigmoid already applied) size N x H x W\n",
    "    pxyz_mu: prediction of parameters (phot, xyz) size N x C=4 x H x W\n",
    "    pxyz_sig: prediction of uncertainties / sigma values (phot, xyz) size N x C=4 x H x W\n",
    "    pxyz_tar: ground truth values (phot, xyz) size N x M x 4 (M being max number of tars)\n",
    "    mask: activation mask of ground truth values (phot, xyz) size N x M\n",
    "Returns:\n",
    "    torch.Tensor (size N x 1)\n",
    "\"\"\"\n",
    "batch_size, nc, hh, ww = pxyz_mu.size()\n",
    "print(f'pxyz_mu shape: [{batch_size} {nc} {hh} {ww}]')\n",
    "log_prob = 0\n",
    "\n",
    "p_mean = p.sum(-1).sum(-1).sum(-1)\n",
    "p_var = (p - p ** 2).sum(-1).sum(-1).sum(-1)  # var estimate of bernoulli\n",
    "print(f'p shape: {p.shape} mean: {p_mean.item():.4f} var: {p_var.item():.4f}')\n",
    "p_gauss = distributions.Normal(p_mean, torch.sqrt(p_var))\n",
    "\n",
    "log_prob = log_prob + p_gauss.log_prob(mask.sum(-1)) * mask.sum(-1)\n",
    "print(f'log_prob version 1: {log_prob.item():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 4, 4])\n",
      "torch.Size([1, 2, 4, 4, 4])\n",
      "torch.Size([32, 4])\n",
      "torch.Size([1, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"GMM LOSS - LOCALIZATION LOSS\"\"\"\n",
    "# print(p)\n",
    "# print(p.shape)\n",
    "# print(p.sum(-1).sum(-1))\n",
    "\n",
    "prob_normed = p / p.sum(-1).sum(-1).sum(-1).view(-1, 1, 1, 1)\n",
    "print(prob_normed.shape)\n",
    "\n",
    "\"\"\"Hacky way to get all prob indices\"\"\"\n",
    "# p_inds [0]=batch_index [1]=prob_3channel_index [2]=x_index [3]=y_index\n",
    "p_inds = tuple((p + 1).nonzero(as_tuple=False).transpose(1, 0))\n",
    "pxyz_mu = pxyz_mu.reshape(batch_size,int(nc/2),2,hh,ww).transpose(2,1)\n",
    "print(pxyz_mu.shape)\n",
    "pxyz_mu = pxyz_mu[p_inds[0], p_inds[1], :, p_inds[2], p_inds[3]]\n",
    "print(pxyz_mu.shape)\n",
    "\n",
    "\"\"\"Convert px shifts to absolute coordinates\"\"\"\n",
    "pxyz_mu[:, 1] += 1\n",
    "pxyz_mu[:, 2] += 1\n",
    "\n",
    "\"\"\"Flatten img dimension --> N x (HxW) x 4\"\"\"\n",
    "pxyz_mu = pxyz_mu.reshape(batch_size, -1, 4)\n",
    "print(pxyz_mu.shape)\n",
    "pxyz_sig = pxyz_sig.reshape(batch_size,int(nc/2),2,hh,ww).transpose(2,1)\n",
    "pxyz_sig = pxyz_sig[p_inds[0], p_inds[1], :, p_inds[2], p_inds[3]].reshape(batch_size, -1, 4)\n",
    "\n",
    "\n",
    "\"\"\"Set up mixture family\"\"\"\n",
    "mix = distributions.Categorical(prob_normed[p_inds].reshape(batch_size, -1))\n",
    "comp = distributions.Independent(distributions.Normal(pxyz_mu, pxyz_sig), 1)\n",
    "gmm = distributions.mixture_same_family.MixtureSameFamily(mix, comp)\n",
    "# print(f'gmm:{gmm}')\n",
    "\n",
    "\"\"\"Calc log probs if there is anything there\"\"\"\n",
    "if mask.sum():\n",
    "    # print(f'pxyz_tar:{pxyz_tar.shape}')\n",
    "    gmm_log = gmm.log_prob(pxyz_tar.transpose(0, 1)).transpose(0, 1)\n",
    "    gmm_log = (gmm_log * mask).sum(-1)\n",
    "    # print(f\"LogProb: {log_prob.mean()}, GMM_log: {gmm_log.mean()}\")\n",
    "    log_prob = log_prob + gmm_log\n",
    "\n",
    "# log_prob = log_prob.reshape(batch_size, 1)  # need?\n",
    "\n",
    "loss = log_prob * (-1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32d9234fb3a060fbd30877034f28c0fca724fa3d0d25a605ad46b1806c555f07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('decode_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
