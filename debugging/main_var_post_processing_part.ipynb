{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, datetime, numpy, os, shutil, sys, time\n",
    "from cmath import inf\n",
    "import socket\n",
    "from pathlib import Path\n",
    "import torch\n",
    "# self-defined modules\n",
    "import decode.evaluation\n",
    "import decode.neuralfitter\n",
    "import decode.neuralfitter.coord_transform\n",
    "import decode.neuralfitter.utils\n",
    "import decode.simulation\n",
    "import decode.utils\n",
    "# from decode.neuralfitter.train.random_simulation import setup_random_simulation\n",
    "from decode.neuralfitter.utils import log_train_val_progress\n",
    "from decode.utils.checkpoint import CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Training Args')\n",
    "\n",
    "    parser.add_argument('-i', '--device', default=None, \n",
    "                        help='Specify the device string (cpu, cuda, cuda:0) and overwrite param.',\n",
    "                        type=str)\n",
    "\n",
    "    parser.add_argument('-p', '--param_file', default=None,\n",
    "                        help='Specify your parameter file (.yml or .json).', type=str)\n",
    "\n",
    "    parser.add_argument('-w', '--num_worker_override',default=None,\n",
    "                        help='Override the number of workers for the dataloaders.',\n",
    "                        type=int)\n",
    "\n",
    "    parser.add_argument('-n', '--no_log', default=False, action='store_true',\n",
    "                        help='Set no log if you do not want to log the current run.')\n",
    "\n",
    "    parser.add_argument('-c', '--log_comment', default=None,\n",
    "                        help='Add a log_comment to the run.')\n",
    "\n",
    "    parser.add_argument('-d', '--data_path_override', default=None,\n",
    "                        help='Specify your path to data', type=str)\n",
    "\n",
    "    parser.add_argument('-is', '--img_size_override', default=None,\n",
    "                        help='Override img size', type=int)\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "args.device = 'cuda'\n",
    "args.param_file ='/home/lingjia/Documents/rpsf/NN/param.yaml'\n",
    "args.data_path_override = '/media/hdd_4T/lingjia/rPSF/20220716_decode_variant_v2/data_train/30k_pt50L5'\n",
    "args.img_size_override = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_trainer(logger, model_out, ckpt_path, device, param):\n",
    "    \"\"\"Set model, optimiser, loss and schedulers\"\"\"\n",
    "    models_available = {\n",
    "        'SigmaMUNet': decode.neuralfitter.models.SigmaMUNet_variant,\n",
    "        'DoubleMUnet': decode.neuralfitter.models.model_param.DoubleMUnet,\n",
    "        'SimpleSMLMNet': decode.neuralfitter.models.model_param.SimpleSMLMNet,\n",
    "    }\n",
    "\n",
    "    model = models_available[param.HyperParameter.architecture]\n",
    "    model = model.parse(param)\n",
    "\n",
    "    model_ls = decode.utils.model_io.LoadSaveModel(model, output_file=model_out)\n",
    "\n",
    "    model = model_ls.load_init()\n",
    "    model = model.to(torch.device(device))\n",
    "\n",
    "    # Small collection of optimisers\n",
    "    optimizer_available = {\n",
    "        'Adam': torch.optim.Adam,\n",
    "        'AdamW': torch.optim.AdamW,\n",
    "        'SGD': torch.optim.SGD\n",
    "    }\n",
    "\n",
    "    optimizer = optimizer_available[param.HyperParameter.optimizer]\n",
    "    optimizer = optimizer(model.parameters(), **param.HyperParameter.opt_param)\n",
    "\n",
    "    \"\"\"Loss function.\"\"\"\n",
    "    criterion = decode.neuralfitter.loss.GaussianMMLoss(\n",
    "        xextent=param.Simulation.psf_extent[0],\n",
    "        yextent=param.Simulation.psf_extent[1],\n",
    "        img_shape=param.Simulation.img_size,\n",
    "        device=device,\n",
    "        chweight_stat=param.HyperParameter.chweight_stat)\n",
    "\n",
    "    \"\"\"Learning Rate and Simulation Scheduling\"\"\"\n",
    "    lr_scheduler_available = {\n",
    "        'ReduceLROnPlateau': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        'StepLR': torch.optim.lr_scheduler.StepLR\n",
    "    }\n",
    "    lr_scheduler = lr_scheduler_available[param.HyperParameter.learning_rate_scheduler]\n",
    "    lr_scheduler = lr_scheduler(optimizer, **param.HyperParameter.learning_rate_scheduler_param)\n",
    "\n",
    "    \"\"\"Checkpointing\"\"\"\n",
    "    checkpoint = CheckPoint(path=ckpt_path)\n",
    "\n",
    "    \"\"\"Setup gradient modification\"\"\"\n",
    "    grad_mod = param.HyperParameter.grad_mod\n",
    "\n",
    "    \"\"\"Log the model (Graph) \"\"\"\n",
    "    try:\n",
    "        dummy = torch.rand((2, param.HyperParameter.channels_in,\n",
    "                            *param.Simulation.img_size), requires_grad=False).to(torch.device(device))\n",
    "        logger.add_graph(model, dummy)\n",
    "\n",
    "    except:\n",
    "        print(\"Did not log graph.\")\n",
    "        # raise RuntimeError(\"Your dummy input is wrong. Please update it.\")\n",
    "\n",
    "    \"\"\"Setup Target generator consisting possibly multiple steps in a transformation sequence.\"\"\"\n",
    "    tar_proc = decode.neuralfitter.utils.processing.TransformSequence(\n",
    "        [\n",
    "            # param_tar --> phot/max, z/z_max, bg/bg_max\n",
    "            decode.neuralfitter.scale_transform.ParameterListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max)\n",
    "        ])\n",
    "\n",
    "    # Split train & val set\n",
    "    train_IDs = numpy.arange(1,101,1).tolist()\n",
    "    val_IDs = numpy.arange(101,111,1).tolist()\n",
    "\n",
    "    train_ds = decode.neuralfitter.dataset.rPSFDataset(root_dir=param.InOut.data_path,\n",
    "                                                       list_IDs=train_IDs, label_path=None, \n",
    "                                                       n_max=param.HyperParameter.max_number_targets,\n",
    "                                                       tar_proc=tar_proc,\n",
    "                                                       img_shape=param.Simulation.img_size)\n",
    "\n",
    "    test_ds = decode.neuralfitter.dataset.rPSFDataset(root_dir=param.InOut.data_path,\n",
    "                                                       list_IDs=val_IDs, label_path=None, \n",
    "                                                       n_max=param.HyperParameter.max_number_targets,\n",
    "                                                       tar_proc=tar_proc,\n",
    "                                                       img_shape=param.Simulation.img_size)\n",
    "\n",
    "    # print(test_ds.label_gen())\n",
    "\n",
    "    \"\"\"Set up post processor\"\"\"\n",
    "    if param.PostProcessing is None:\n",
    "        post_processor = decode.neuralfitter.post_processing.NoPostProcessing(xy_unit='px',\n",
    "                                                                              px_size=param.Camera.px_size)\n",
    "\n",
    "    elif param.PostProcessing == 'LookUp':\n",
    "        post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "\n",
    "            decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max),\n",
    "\n",
    "            decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "            decode.neuralfitter.post_processing.LookUpPostProcessing(\n",
    "                raw_th=param.PostProcessingParam.raw_th,\n",
    "                pphotxyzbg_mapping=[0, 1, 2, 3, 4, -1],\n",
    "                xy_unit='px',\n",
    "                px_size=param.Camera.px_size)\n",
    "        ])\n",
    "\n",
    "    elif param.PostProcessing in ('SpatialIntegration', 'NMS'):  # NMS as legacy support\n",
    "        post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "            # out_tar --> out_tar: photo*photo_max, z*z_max, bg*bg_max\n",
    "            decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max),\n",
    "            # offset --> coordinate e.g., 0.2 --> 10.2 \n",
    "            decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "            decode.neuralfitter.post_processing.SpatialIntegration(\n",
    "                raw_th=param.PostProcessingParam.raw_th, # 0.5\n",
    "                xy_unit='px')\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \"\"\"Evaluation Specification\"\"\"\n",
    "    matcher = decode.evaluation.match_emittersets.GreedyHungarianMatching.parse(param)\n",
    "    # matcher = None\n",
    "\n",
    "    return train_ds, test_ds, model, model_ls, optimizer, criterion, lr_scheduler, grad_mod, post_processor, matcher, checkpoint\n",
    "\n",
    "\n",
    "def setup_dataloader(param, train_ds, test_ds=None):\n",
    "    \"\"\"Set up dataloader\"\"\"\n",
    "\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        dataset=train_ds,\n",
    "        batch_size=param.HyperParameter.batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        num_workers=param.Hardware.num_worker_train,\n",
    "        pin_memory=True,\n",
    "        collate_fn=decode.neuralfitter.utils.dataloader_customs.smlm_collate)\n",
    "\n",
    "    if test_ds is not None:\n",
    "\n",
    "        test_dl = torch.utils.data.DataLoader(\n",
    "            dataset=test_ds,\n",
    "            batch_size=param.HyperParameter.batch_size,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            num_workers=param.Hardware.num_worker_train,\n",
    "            pin_memory=False,\n",
    "            collate_fn=decode.neuralfitter.utils.dataloader_customs.smlm_collate)\n",
    "    else:\n",
    "\n",
    "        test_dl = None\n",
    "\n",
    "    return train_dl, test_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated.\n",
      "Model initialised as specified in the constructor.\n",
      "Epoch0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 Train Time:0.89 Loss_mean_ep:1.97e+07: 100%|████████████████████████| 2/2 [00:00<00:00,  2.18it/s]\n",
      "0 Test Time:0.069 Loss_mean_ep:1.39e+05: 100%|████| 1/1 [00:00<00:00,  9.17it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"TRIAN AND TEST 1 EPOCH - BEOFRE TUNE POST-PROCESS PART\"\"\"\n",
    "param_file = Path(args.param_file)\n",
    "param = decode.utils.param_io.ParamHandling().load_params(param_file)\n",
    "\n",
    "# add meta information - Meta=namespace(version='0.10.0'),\n",
    "param.Meta.version = decode.utils.bookkeeping.decode_state()\n",
    "\n",
    "\"\"\"Experiment ID\"\"\"\n",
    "if param.InOut.checkpoint_init is None:\n",
    "    experiment_id = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    from_ckpt = False\n",
    "    if args.log_comment:\n",
    "        experiment_id = experiment_id + '_' + args.log_comment\n",
    "else:\n",
    "    from_ckpt = True\n",
    "    experiment_id = Path(param.InOut.checkpoint_init).parent.name\n",
    "\n",
    "\"\"\"Set up unique folder for experiment\"\"\"\n",
    "if not from_ckpt:\n",
    "    experiment_path = Path(param.InOut.experiment_out) / Path(experiment_id)\n",
    "else:\n",
    "    experiment_path = Path(param.InOut.checkpoint_init).parent\n",
    "\n",
    "if not experiment_path.parent.exists():\n",
    "    experiment_path.parent.mkdir()\n",
    "\n",
    "if not from_ckpt:\n",
    "    experiment_path.mkdir(exist_ok=False)\n",
    "\n",
    "model_out = experiment_path / Path('model.pt')\n",
    "ckpt_path = experiment_path / Path('ckpt.pt')\n",
    "\n",
    "# Modify parameters\n",
    "if args.num_worker_override is not None:\n",
    "    param.Hardware.num_worker_train = args.num_worker_override\n",
    "\n",
    "\"\"\"Hardware / Server stuff.\"\"\"\n",
    "if args.device is not None:\n",
    "    device = args.device\n",
    "    # param.Hardware.device_simulation = device_overwrite  # lazy assumption\n",
    "else:\n",
    "    device = param.Hardware.device\n",
    "\n",
    "if args.data_path_override is not None:\n",
    "    param.InOut.data_path = args.data_path_override\n",
    "\n",
    "if args.img_size_override is not None:\n",
    "    param.Simulation.img_size = [args.img_size_override,args.img_size_override]\n",
    "    param.Simulation.psf_extent = [[-0.5, args.img_size_override-0.5],\n",
    "                                    [-0.5, args.img_size_override-0.5], None]\n",
    "\n",
    "    param.TestSet.frame_extent = param.Simulation.psf_extent\n",
    "    param.TestSet.img_size = param.Simulation.img_size\n",
    "\n",
    "# Backup the parameter file under the network output path with the experiments ID\n",
    "param_backup_in = experiment_path / Path('param_run_in').with_suffix(param_file.suffix)\n",
    "shutil.copy(param_file, param_backup_in)\n",
    "\n",
    "param_backup = experiment_path / Path('param_run').with_suffix(param_file.suffix)\n",
    "decode.utils.param_io.ParamHandling().write_params(param_backup, param)\n",
    "\n",
    "if sys.platform in ('linux', 'darwin'):\n",
    "    os.nice(param.Hardware.unix_niceness)\n",
    "elif param.Hardware.unix_niceness is not None:\n",
    "    print(f\"Cannot set niceness on platform {sys.platform}. You probably do not need to worry.\")\n",
    "\n",
    "torch.set_num_threads(param.Hardware.torch_threads)\n",
    "\n",
    "\"\"\"Setup Log System\"\"\"\n",
    "if args.no_log:\n",
    "    logger = decode.neuralfitter.utils.logger.NoLog()\n",
    "\n",
    "else:\n",
    "    log_folder = experiment_path\n",
    "\n",
    "    logger = decode.neuralfitter.utils.logger.MultiLogger(\n",
    "        [decode.neuralfitter.utils.logger.SummaryWriter(log_dir=log_folder,\n",
    "                                                        filter_keys=[\"dx_red_mu\", \"dx_red_sig\",\n",
    "                                                                        \"dy_red_mu\",\n",
    "                                                                        \"dy_red_sig\", \"dz_red_mu\",\n",
    "                                                                        \"dz_red_sig\",\n",
    "                                                                        \"dphot_red_mu\",\n",
    "                                                                        \"dphot_red_sig\"]),\n",
    "            decode.neuralfitter.utils.logger.DictLogger()])\n",
    "\n",
    "# sim_train, sim_test = setup_random_simulation(param)\n",
    "ds_train, ds_test, model, model_ls, optimizer, criterion, lr_scheduler, grad_mod, post_processor, matcher, ckpt = setup_trainer(logger, model_out, ckpt_path, device, param)\n",
    "\n",
    "dl_train, dl_test = setup_dataloader(param, ds_train, ds_test)\n",
    "\n",
    "if from_ckpt:\n",
    "    ckpt = decode.utils.checkpoint.CheckPoint.load(param.InOut.checkpoint_init)\n",
    "    model.load_state_dict(ckpt.model_state)\n",
    "    optimizer.load_state_dict(ckpt.optimizer_state)\n",
    "    lr_scheduler.load_state_dict(ckpt.lr_sched_state)\n",
    "    first_epoch = ckpt.step + 1\n",
    "    model = model.train()\n",
    "    print(f'Resuming training from checkpoint ' + experiment_id)\n",
    "else:\n",
    "    first_epoch = 0\n",
    "\n",
    "best_val_loss = inf\n",
    "i = first_epoch\n",
    "# for i in range(first_epoch, param.HyperParameter.epochs):\n",
    "logger.add_scalar('learning/learning_rate', optimizer.param_groups[0]['lr'], i)\n",
    "print(f'Epoch{i}')\n",
    "# if i >= 1:\n",
    "_ = decode.neuralfitter.train_val_impl.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss=criterion,\n",
    "    dataloader=dl_train,\n",
    "    grad_rescale=param.HyperParameter.moeller_gradient_rescale,\n",
    "    grad_mod=grad_mod,\n",
    "    epoch=i,\n",
    "    device=torch.device(device),\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# val_loss=avg of loss for all batches\n",
    "# test_out=list of network_output: [\"loss\", \"x\", \"y_out\", \"y_tar\", \"weight\", \"em_tar\"]\n",
    "val_loss, test_out = decode.neuralfitter.train_val_impl.test(\n",
    "    model=model,\n",
    "    loss=criterion,\n",
    "    dataloader=dl_test,\n",
    "    epoch=i,\n",
    "    device=torch.device(device))\n",
    "# print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT LOG\n",
    "# log_train_val_progress.post_process_log_test(loss_cmp=test_out.loss,\n",
    "#                                             loss_scalar=val_loss,\n",
    "#                                             x=test_out.x, y_out=test_out.y_out,\n",
    "#                                             y_tar=test_out.y_tar,\n",
    "#                                             weight=test_out.weight,\n",
    "#                                             em_tar=ds_test.emitter(),\n",
    "#                                             px_border=-0.5, px_size=1.,\n",
    "#                                             post_processor=post_processor,\n",
    "#                                             matcher=matcher, logger=logger,\n",
    "#                                             step=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"POST_PROCESSOR\"\"\"\n",
    "post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "    # out_tar --> out_tar: photo*photo_max, z*z_max, bg*bg_max\n",
    "    decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "        phot_max=param.Scaling.phot_max,\n",
    "        z_max=param.Scaling.z_max,\n",
    "        bg_max=param.Scaling.bg_max),\n",
    "    # offset --> coordinate e.g., 0.2 --> 10.2\n",
    "    decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "    decode.neuralfitter.post_processing.SpatialIntegration(\n",
    "        raw_th=param.PostProcessingParam.raw_th, # 0.5\n",
    "        xy_unit='px')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INVERSEPARAMLISTRESCALE CHECK'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"INVERSEPARAMLISTRESCALE CHECK\"\"\"\n",
    "# change corresponding index\n",
    "# num channels = 3\n",
    "# p=0,1,2 phot=3,4,5 x=6,7,8 y=9,10,11 z=12,13,14 phot_sig=15,16,17 x_sig=18,19,20, y_sig=21,22,23, z_sig=24,25,26, bg=27\n",
    "# num channels = 2\n",
    "# p=0,1 phot=2,3 x=4,5 y=6,7 z=8,9 phot_sig=10,11 x_sig=12,13, y_sig=14,15, z_sig=16,17, bg=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SIMULATED INPUT X AND GROUND-TRUTH TARGET\"\"\"\n",
    "# INPUT\n",
    "x = torch.randn(1,1,4,4).to('cuda')\n",
    "# TARGET\n",
    "param_tar = torch.zeros(1,60,4)\n",
    "param_tar_v = torch.randn(2,4)\n",
    "param_tar[0,:2,:] = param_tar_v\n",
    "\n",
    "mask_tar = torch.zeros(1,60)\n",
    "mask_tar[0,:2] = 1\n",
    "\n",
    "bg = torch.ones((1,4,4))*5\n",
    "\n",
    "target = (param_tar.to('cuda'), mask_tar.to('cuda'), bg.to('cuda'))\n",
    "# WEIGHT\n",
    "weight = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_out: torch.Size([1, 19, 4, 4])\n",
      "tensor([11.5000, 35.5000, 59.5000, 83.5000])\n",
      "x_offset:\n",
      "tensor([[[[-0.5418,  0.8828, -0.8397, -0.3643],\n",
      "          [ 0.7593, -0.8372,  0.5576, -0.8078],\n",
      "          [ 0.3342, -0.0592, -0.9278, -0.5546],\n",
      "          [ 0.4561,  0.5927,  0.2704,  0.7213]],\n",
      "\n",
      "         [[-0.8458,  0.0293,  0.9037, -0.2904],\n",
      "          [-0.7090,  0.9806, -0.0610, -0.5777],\n",
      "          [-0.4695,  0.1654, -0.3924,  0.8914],\n",
      "          [ 0.7908, -0.2937, -0.7683, -0.8147]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "x_mesh:\n",
      "tensor([[[[11.5000, 11.5000, 11.5000, 11.5000],\n",
      "          [35.5000, 35.5000, 35.5000, 35.5000],\n",
      "          [59.5000, 59.5000, 59.5000, 59.5000],\n",
      "          [83.5000, 83.5000, 83.5000, 83.5000]],\n",
      "\n",
      "         [[11.5000, 11.5000, 11.5000, 11.5000],\n",
      "          [35.5000, 35.5000, 35.5000, 35.5000],\n",
      "          [59.5000, 59.5000, 59.5000, 59.5000],\n",
      "          [83.5000, 83.5000, 83.5000, 83.5000]]]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"OUTPUT OF SIMULATED INPUT X AND OFFSET2COORDINATE CHECK\"\"\"\n",
    "output = model(x)\n",
    "print(f'y_out: {output.shape}')\n",
    "\n",
    "from decode.neuralfitter.target_generator import UnifiedEmbeddingTarget\n",
    "off_psf = UnifiedEmbeddingTarget(xextent=param.TestSet.frame_extent[0],\n",
    "                                    yextent=param.TestSet.frame_extent[1],\n",
    "                                    img_shape=(4,4), roi_size=1)\n",
    "\n",
    "print(off_psf._bin_ctr_x)\n",
    "\n",
    "xv, yv = torch.meshgrid([off_psf._bin_ctr_x, off_psf._bin_ctr_y])\n",
    "_x_mesh = xv.unsqueeze(0)\n",
    "_y_mesh = yv.unsqueeze(0)\n",
    "\n",
    "x_offset = output[:, 4:6]\n",
    "print(f'x_offset:\\n{x_offset}')\n",
    "print(f'x_mesh:\\n{_x_mesh[:,None].repeat(1,2, 1, 1)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _subpx_to_absolute(self, x_offset, y_offset):\n",
    "    \"\"\"\n",
    "    Convert subpixel pointers to absolute coordinates. Actual implementation\n",
    "\n",
    "    Args:\n",
    "        x_offset: N x H x W\n",
    "        y_offset: N x H x W\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    batch_size = x_offset.size(0)\n",
    "    x_coord = _x_mesh[:,None].repeat(batch_size, 1, 1).to(x_offset.device) + x_offset\n",
    "    y_coord = _y_mesh.repeat(batch_size, 1, 1).to(y_offset.device) + y_offset\n",
    "    return x_coord, y_coord\n",
    "\n",
    "def Offset2Coordinate(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Forward frames through post-processor.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): features to be converted. Expecting x/y coordinates in channel index 2, 3.\n",
    "            expected shape :math:`(N, C, H, W)`\n",
    "    \"\"\"\n",
    "\n",
    "    if x.dim() != 4:\n",
    "        raise ValueError(\"Wrong dimensionality. Needs to be N x C x H x W.\")\n",
    "\n",
    "    \"\"\"Convert the channel values to coordinates\"\"\"\n",
    "    x_coord, y_coord = _subpx_to_absolute(x[:, 6:9], x[:, 9:12])\n",
    "\n",
    "    output_converted = x.clone()\n",
    "    output_converted[:, 6:9] = x_coord\n",
    "    output_converted[:, 9:12] = y_coord\n",
    "\n",
    "    return output_converted\n",
    "\n",
    "torch.set_printoptions(precision=4,sci_mode=False)\n",
    "# print(output)\n",
    "# print(Offset2Coordinate(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SIMULATED OUTPUT X0\"\"\"\n",
    "torch.manual_seed(0)\n",
    "# x0 = torch.randn(2,28,2,2)\n",
    "x0 = torch.randn(3,19,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_clip:torch.Size([3, 1, 2, 4, 4])\n",
      "max_mask1:torch.Size([3, 1, 2, 4, 4])\n",
      "p_ps1:torch.Size([3, 1, 2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SPATIALINTEGRATION CHECK - P1 IN SpatialIntegration FORWARD\"\"\"\n",
    "from typing import Union, Callable\n",
    "def _nms(p: torch.Tensor, p_aggregation, raw_th, split_th) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Non-Maximum Suppresion\n",
    "    Args:\n",
    "        p:\n",
    "    \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        p_copy = p.clone()\n",
    "\n",
    "        \"\"\"Probability values > 0.3 are regarded as possible locations\"\"\"\n",
    "        p_clip = torch.where(p > raw_th, p, torch.zeros_like(p))[:, None]\n",
    "        print(f'p_clip:{p_clip.shape}')\n",
    "\n",
    "        \"\"\"localize maximum values within a 3x3 patch\"\"\"\n",
    "        pool = torch.nn.functional.max_pool3d(p_clip, kernel_size=(1,3,3), stride=1, padding=(0,1,1))\n",
    "        max_mask1 = torch.eq(p[:, None], pool).float()\n",
    "        print(f'max_mask1:{max_mask1.shape}')\n",
    "\n",
    "        \"\"\"Add probability values from the 4 adjacent pixels\"\"\"\n",
    "        diag = 0.  # 1/np.sqrt(2)\n",
    "        filt = torch.tensor([[diag, 1., diag], [1, 1, 1], [diag, 1, diag]]).unsqueeze(0).unsqueeze(0).to(p.device)\n",
    "        conv = [torch.nn.functional.conv2d(p[:, None, idx], filt, padding=1) for idx in range(p.shape[1])]\n",
    "        conv = torch.cat(conv,dim=1)[:,None]\n",
    "        p_ps1 = max_mask1 * conv\n",
    "        print(f'p_ps1:{p_ps1.shape}')\n",
    "\n",
    "        \"\"\"\n",
    "        In order do be able to identify two fluorophores in adjacent pixels we look for\n",
    "        probablity values > 0.6 that are not part of the first mask\n",
    "        \"\"\"\n",
    "        p_copy *= (1 - max_mask1[:, 0])\n",
    "        # p_clip = torch.where(p_copy > split_th, p_copy, torch.zeros_like(p_copy))[:, None]\n",
    "        max_mask2 = torch.where(p_copy > split_th, torch.ones_like(p_copy), torch.zeros_like(p_copy))[:, None]\n",
    "        p_ps2 = max_mask2 * conv\n",
    "\n",
    "        \"\"\"This is our final clustered probablity which we then threshold (normally > 0.7)\n",
    "        to get our final discrete locations\"\"\"\n",
    "        p_ps = p_aggregation(p_ps1, p_ps2)\n",
    "        assert p_ps.size(1) == 1\n",
    "\n",
    "        return p_ps.squeeze(1)\n",
    "\n",
    "def set_p_aggregation(p_aggr: Union[str, Callable]) -> Callable:\n",
    "    \"\"\"\n",
    "    Sets the p_aggregation by string or callable. Return s Callable\n",
    "\n",
    "    Args:\n",
    "        p_aggr: probability aggregation\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(p_aggr, str):\n",
    "\n",
    "        if p_aggr == 'sum':\n",
    "            return torch.add\n",
    "        elif p_aggr == 'max':\n",
    "            return torch.max\n",
    "        elif p_aggr == 'norm_sum':\n",
    "            def norm_sum(*args):\n",
    "                return torch.clamp(torch.add(*args), 0., 1.)\n",
    "\n",
    "            return norm_sum\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    else:\n",
    "        return p_aggr\n",
    "\n",
    "\n",
    "x = x0.clone()\n",
    "p_aggregation = set_p_aggregation('norm_sum')\n",
    "raw_th = 0.3\n",
    "_split_th = 0.6\n",
    "x[:, 0:2] = _nms(x[:, 0:2], p_aggregation, raw_th, _split_th)\n",
    "# print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SPATIALINTEGRATION CHECK - P2 IN LookUpPostProcessing INITIAL\"\"\"\n",
    "pphotxyz_mapping: Union[list, tuple] = (0,1, 2,3, 4,5, 6,7, 8,9)\n",
    "photxyz_sigma_mapping: Union[list, tuple, None] = (10,11, 12,13, 14,15, 16,17)\n",
    "bg_mapping: Union[list, tuple] = (-1)\n",
    "\n",
    "assert len(pphotxyz_mapping) == 10, \"Wrong length of mapping.\"\n",
    "if photxyz_sigma_mapping is not None:\n",
    "    assert len(photxyz_sigma_mapping) == 8, \"Wrong length of sigma mapping.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_mapped: torch.Size([3, 10, 4, 4])\n",
      "prob: tensor([0.7372, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.3124, 1.0000, 1.0000, 1.0000, 1.0000, 0.5836, 1.0000, 1.0000])\n",
      "features reshape: torch.Size([3, 4, 2, 4, 4])\n",
      "after looup features,frame_ix:torch.Size([17]),features:torch.Size([4, 17])\n",
      "features[0,:]: tensor([ 0.4397,  2.3022, -1.4689,  0.1778, -0.3952, -0.4462, -1.5312, -1.2341,\n",
      "         1.8197,  0.9094,  1.2464,  0.1151,  1.6193,  0.4637, -0.3380, -0.2995,\n",
      "         0.8155])\n",
      "features reshape: torch.Size([3, 4, 2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SPATIALINTEGRATION CHECK - P3 IN LookUpPostProcessing FORWARD\"\"\"\n",
    "x_mapped = x[:, pphotxyz_mapping]\n",
    "print(f'x_mapped: {x_mapped.shape}')\n",
    "# print(x_mapped)\n",
    "\n",
    "\"\"\"Filter\"\"\"\n",
    "def _filter(detection) -> torch.BoolTensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        detection: any tensor that should be thresholded\n",
    "    Returns:\n",
    "        boolean with active px\n",
    "    \"\"\"\n",
    "\n",
    "    return detection >= raw_th\n",
    "\n",
    "active_px = _filter(x_mapped[:, 0:2])  # 0th ch. is detection channel\n",
    "prob = x_mapped[:, 0:2][active_px]\n",
    "print(f'prob: {prob}')\n",
    "\n",
    "\n",
    "\"\"\"Look-Up in channels\"\"\"\n",
    "# features, active_px = x_mapped[:, 3:], active_px\n",
    "def _lookup_features(features: torch.Tensor, active_px: torch.Tensor) -> tuple:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        features: size :math:`(N, C, H, W)`\n",
    "        active_px: size :math:`(N, H, W)`\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: batch-ix, size :math: `M`\n",
    "        torch.Tensor: extracted features size :math:`(C, M)`\n",
    "    \"\"\"\n",
    "    batch_size, nc, hh, ww = features.size()\n",
    "    features = features.reshape(batch_size,int(nc/2),2,hh,ww)\n",
    "    print(f'features reshape: {features.shape}')\n",
    "    # print(features)\n",
    "\n",
    "    assert features.dim() == 5\n",
    "    assert active_px.dim() == features.dim() - 1\n",
    "\n",
    "    batch_ix = active_px.nonzero(as_tuple=False)[:, 0] # before [:,0] is Nx4 = [batch_index, 3channel_index, x_index, y_index]\n",
    "    # print(batch_ix)\n",
    "    features_active = features.permute(1, 0, 2, 3, 4)[:, active_px]\n",
    "\n",
    "    return batch_ix, features_active\n",
    "\n",
    "frame_ix, features = _lookup_features(x_mapped[:, 2:], active_px)\n",
    "print(f'after looup features,frame_ix:{frame_ix.shape},features:{features.shape}')\n",
    "print(f'features[0,:]: {features[0,:]}')\n",
    "xyz = features[1:4].transpose(0, 1)\n",
    "# print(xyz)\n",
    "\n",
    "\n",
    "\"\"\"If sigma mapping is present, get those values as well.\"\"\"\n",
    "if photxyz_sigma_mapping is not None:\n",
    "    sigma = x[:, photxyz_sigma_mapping]\n",
    "    _, features_sigma = _lookup_features(sigma, active_px)\n",
    "\n",
    "    xyz_sigma = features_sigma[1:4].transpose(0, 1).cpu()\n",
    "    phot_sigma = features_sigma[0].cpu()\n",
    "else:\n",
    "    xyz_sigma = None\n",
    "    phot_sigma = None"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32d9234fb3a060fbd30877034f28c0fca724fa3d0d25a605ad46b1806c555f07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('decode_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
