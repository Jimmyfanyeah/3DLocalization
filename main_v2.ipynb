{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from ast import List\n",
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import socket\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "import decode.evaluation\n",
    "import decode.neuralfitter\n",
    "import decode.neuralfitter.coord_transform\n",
    "import decode.neuralfitter.utils\n",
    "import decode.simulation\n",
    "import decode.utils\n",
    "# from decode.neuralfitter.train.random_simulation import setup_random_simulation\n",
    "from decode.neuralfitter.utils import log_train_val_progress\n",
    "from decode.utils.checkpoint import CheckPoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Training Args')\n",
    "\n",
    "    parser.add_argument('-i', '--device', default=None, \n",
    "                        help='Specify the device string (cpu, cuda, cuda:0) and overwrite param.',\n",
    "                        type=str)\n",
    "\n",
    "    parser.add_argument('-p', '--param_file', default=None,\n",
    "                        help='Specify your parameter file (.yml or .json).', type=str)\n",
    "\n",
    "    # parser.add_argument('-d', '--debug', default=False, action='store_true',\n",
    "    #                     help='Debug the specified parameter file. Will reduce ds size for example.')\n",
    "\n",
    "    parser.add_argument('-w', '--num_worker_override',default=None,\n",
    "                        help='Override the number of workers for the dataloaders.',\n",
    "                        type=int)\n",
    "\n",
    "    parser.add_argument('-n', '--no_log', default=False, action='store_true',\n",
    "                        help='Set no log if you do not want to log the current run.')\n",
    "\n",
    "    # parser.add_argument('-l', '--log_folder', default=None,\n",
    "    #                     help='Specify the (parent) folder you want to log to. If rel-path, relative to DECODE root.')\n",
    "\n",
    "    parser.add_argument('-c', '--log_comment', default=None,\n",
    "                        help='Add a log_comment to the run.')\n",
    "\n",
    "    parser.add_argument('-d', '--data_path_override', default=None,\n",
    "                        help='Specify your path to data', type=str)\n",
    "\n",
    "    parser.add_argument('-is', '--img_size_override', default=None,\n",
    "                        help='Override img size', type=list)\n",
    "\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_trainer(logger, model_out, ckpt_path, device, param):\n",
    "    \"\"\"Set model, optimiser, loss and schedulers\"\"\"\n",
    "    models_available = {\n",
    "        'SigmaMUNet': decode.neuralfitter.models.SigmaMUNet,\n",
    "        'DoubleMUnet': decode.neuralfitter.models.model_param.DoubleMUnet,\n",
    "        'SimpleSMLMNet': decode.neuralfitter.models.model_param.SimpleSMLMNet,\n",
    "    }\n",
    "\n",
    "    model = models_available[param.HyperParameter.architecture]\n",
    "    model = model.parse(param)\n",
    "\n",
    "    model_ls = decode.utils.model_io.LoadSaveModel(model, output_file=model_out)\n",
    "\n",
    "    model = model_ls.load_init()\n",
    "    model = model.to(torch.device(device))\n",
    "\n",
    "    # Small collection of optimisers\n",
    "    optimizer_available = {\n",
    "        'Adam': torch.optim.Adam,\n",
    "        'AdamW': torch.optim.AdamW\n",
    "    }\n",
    "\n",
    "    optimizer = optimizer_available[param.HyperParameter.optimizer]\n",
    "    optimizer = optimizer(model.parameters(), **param.HyperParameter.opt_param)\n",
    "\n",
    "    \"\"\"Loss function.\"\"\"\n",
    "    criterion = decode.neuralfitter.loss.GaussianMMLoss(\n",
    "        xextent=param.Simulation.psf_extent[0],\n",
    "        yextent=param.Simulation.psf_extent[1],\n",
    "        img_shape=param.Simulation.img_size,\n",
    "        device=device,\n",
    "        chweight_stat=param.HyperParameter.chweight_stat)\n",
    "\n",
    "    \"\"\"Learning Rate and Simulation Scheduling\"\"\"\n",
    "    lr_scheduler_available = {\n",
    "        'ReduceLROnPlateau': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        'StepLR': torch.optim.lr_scheduler.StepLR\n",
    "    }\n",
    "    lr_scheduler = lr_scheduler_available[param.HyperParameter.learning_rate_scheduler]\n",
    "    lr_scheduler = lr_scheduler(optimizer, **param.HyperParameter.learning_rate_scheduler_param)\n",
    "\n",
    "    \"\"\"Checkpointing\"\"\"\n",
    "    checkpoint = CheckPoint(path=ckpt_path)\n",
    "\n",
    "    \"\"\"Setup gradient modification\"\"\"\n",
    "    grad_mod = param.HyperParameter.grad_mod\n",
    "\n",
    "    \"\"\"Log the model (Graph) \"\"\"\n",
    "    try:\n",
    "        dummy = torch.rand((2, param.HyperParameter.channels_in,\n",
    "                            *param.Simulation.img_size), requires_grad=False).to(torch.device(device))\n",
    "        logger.add_graph(model, dummy)\n",
    "\n",
    "    except:\n",
    "        print(\"Did not log graph.\")\n",
    "        # raise RuntimeError(\"Your dummy input is wrong. Please update it.\")\n",
    "\n",
    "    \"\"\"Transform input data, compute weight mask and target data\"\"\"\n",
    "    # frame_proc: x --> (x-offset)/scale\n",
    "    # frame_proc = decode.neuralfitter.scale_transform.AmplitudeRescale.parse(param)\n",
    "    # bg_frame_proc = None\n",
    "\n",
    "    # if param.HyperParameter.emitter_label_photon_min is not None:\n",
    "    #     # select emitters with photon > emitter_label_photon_min\n",
    "    #     em_filter = decode.neuralfitter.em_filter.PhotonFilter(\n",
    "    #         param.HyperParameter.emitter_label_photon_min)\n",
    "    # else:\n",
    "    #     em_filter = decode.neuralfitter.em_filter.NoEmitterFilter()\n",
    "\n",
    "    # tar_frame_ix_train = (0, 0)\n",
    "    # tar_frame_ix_test = (0, param.TestSet.test_size)\n",
    "\n",
    "    \"\"\"Setup Target generator consisting possibly multiple steps in a transformation sequence.\"\"\"\n",
    "    tar_proc = decode.neuralfitter.utils.processing.TransformSequence(\n",
    "        [\n",
    "            # param_tar --> phot/max, z/z_max, bg/bg_max\n",
    "            decode.neuralfitter.scale_transform.ParameterListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max)\n",
    "        ])\n",
    "\n",
    "    train_IDs = numpy.arange(1,9001,1).tolist()\n",
    "    val_IDs = numpy.arange(9001,10001,1).tolist()\n",
    "\n",
    "    train_ds = decode.neuralfitter.dataset.rPSFDataset(root_dir=param.InOut.data_path,\n",
    "                                                       list_IDs=train_IDs, label_path=None, \n",
    "                                                       n_max=param.HyperParameter.max_number_targets,\n",
    "                                                       tar_proc=tar_proc,\n",
    "                                                       img_shape=param.Simulation.img_size)\n",
    "\n",
    "    test_ds = decode.neuralfitter.dataset.rPSFDataset(root_dir=param.InOut.data_path,\n",
    "                                                       list_IDs=val_IDs, label_path=None, \n",
    "                                                       n_max=param.HyperParameter.max_number_targets,\n",
    "                                                       tar_proc=tar_proc,\n",
    "                                                       img_shape=param.Simulation.img_size)\n",
    "\n",
    "    \"\"\"Set up post processor\"\"\"\n",
    "    if param.PostProcessing is None:\n",
    "        post_processor = decode.neuralfitter.post_processing.NoPostProcessing(xy_unit='px',\n",
    "                                                                              px_size=param.Camera.px_size)\n",
    "\n",
    "    elif param.PostProcessing == 'LookUp':\n",
    "        post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "\n",
    "            decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max),\n",
    "\n",
    "            decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "            decode.neuralfitter.post_processing.LookUpPostProcessing(\n",
    "                raw_th=param.PostProcessingParam.raw_th,\n",
    "                pphotxyzbg_mapping=[0, 1, 2, 3, 4, -1],\n",
    "                xy_unit='px',\n",
    "                px_size=param.Camera.px_size)\n",
    "        ])\n",
    "\n",
    "    elif param.PostProcessing in ('SpatialIntegration', 'NMS'):  # NMS as legacy support\n",
    "        post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "            # out_tar --> out_tar: photo*photo_max, z*z_max, bg*bg_max\n",
    "            decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max),\n",
    "            # offset --> coordinate e.g., 0.2 --> 10.2 \n",
    "            decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "            decode.neuralfitter.post_processing.SpatialIntegration(\n",
    "                raw_th=param.PostProcessingParam.raw_th, # 0.5\n",
    "                xy_unit='px')\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \"\"\"Evaluation Specification\"\"\"\n",
    "    matcher = decode.evaluation.match_emittersets.GreedyHungarianMatching.parse(param)\n",
    "    # matcher = None\n",
    "\n",
    "    return train_ds, test_ds, model, model_ls, optimizer, criterion, lr_scheduler, grad_mod, post_processor, matcher, checkpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dataloader(param, train_ds, test_ds=None):\n",
    "    \"\"\"Set up dataloader\"\"\"\n",
    "\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        dataset=train_ds,\n",
    "        batch_size=param.HyperParameter.batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        num_workers=param.Hardware.num_worker_train,\n",
    "        pin_memory=True,\n",
    "        collate_fn=decode.neuralfitter.utils.dataloader_customs.smlm_collate)\n",
    "\n",
    "    if test_ds is not None:\n",
    "\n",
    "        test_dl = torch.utils.data.DataLoader(\n",
    "            dataset=test_ds,\n",
    "            batch_size=param.HyperParameter.batch_size,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            num_workers=param.Hardware.num_worker_train,\n",
    "            pin_memory=False,\n",
    "            collate_fn=decode.neuralfitter.utils.dataloader_customs.smlm_collate)\n",
    "    else:\n",
    "\n",
    "        test_dl = None\n",
    "\n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "args.device='cuda:0'\n",
    "args.param_file='/home/lingjia/Documents/rPSF/NN/param_v2.yaml'\n",
    "args.data_path_override='/media/hdd/rPSF_data/rPSF/train/0620_uniformFlux'\n",
    "args.img_size_override=96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lingjia/Documents/rPSF/NN/main_v2.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000004vscode-remote?line=49'>50</a>\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mimg_size_override \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000004vscode-remote?line=50'>51</a>\u001b[0m     param\u001b[39m.\u001b[39mSimulation\u001b[39m.\u001b[39mimg_size \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mimg_size_override\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000004vscode-remote?line=51'>52</a>\u001b[0m     param\u001b[39m.\u001b[39mSimulation\u001b[39m.\u001b[39mpsf_extent \u001b[39m=\u001b[39m [[\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m,args\u001b[39m.\u001b[39;49mimg_size_override[\u001b[39m0\u001b[39;49m]\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000004vscode-remote?line=52'>53</a>\u001b[0m                                     [\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m,args\u001b[39m.\u001b[39mimg_size_override[\u001b[39m0\u001b[39m]\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m], \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000004vscode-remote?line=54'>55</a>\u001b[0m \u001b[39m# Backup the parameter file under the network output path with the experiments ID\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000004vscode-remote?line=55'>56</a>\u001b[0m param_backup_in \u001b[39m=\u001b[39m experiment_path \u001b[39m/\u001b[39m Path(\u001b[39m'\u001b[39m\u001b[39mparam_run_in\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mwith_suffix(param_file\u001b[39m.\u001b[39msuffix)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "    \"\"\"Load Parameters and back them up to the network output directory\"\"\"\n",
    "    param_file = Path(args.param_file)\n",
    "    param = decode.utils.param_io.ParamHandling().load_params(param_file)\n",
    "\n",
    "    # auto-set some parameters (will be stored in the backup copy)\n",
    "    # param = decode.utils.param_io.autoset_scaling(param)\n",
    "\n",
    "    # add meta information - Meta=namespace(version='0.10.0'),\n",
    "    param.Meta.version = decode.utils.bookkeeping.decode_state()\n",
    "\n",
    "    \"\"\"Experiment ID\"\"\"\n",
    "    if param.InOut.checkpoint_init is None:\n",
    "        experiment_id = datetime.datetime.now().strftime(\n",
    "            \"%Y-%m-%d_%H-%M-%S\") + '_' + socket.gethostname()\n",
    "        from_ckpt = False\n",
    "        if args.log_comment:\n",
    "            experiment_id = experiment_id + '_' + args.log_comment\n",
    "    else:\n",
    "        from_ckpt = True\n",
    "        experiment_id = Path(param.InOut.checkpoint_init).parent.name\n",
    "\n",
    "    \"\"\"Set up unique folder for experiment\"\"\"\n",
    "    if not from_ckpt:\n",
    "        experiment_path = Path(param.InOut.experiment_out) / Path(experiment_id)\n",
    "    else:\n",
    "        experiment_path = Path(param.InOut.checkpoint_init).parent\n",
    "\n",
    "    if not experiment_path.parent.exists():\n",
    "        experiment_path.parent.mkdir()\n",
    "\n",
    "    if not from_ckpt:\n",
    "        experiment_path.mkdir(exist_ok=False)\n",
    "\n",
    "    model_out = experiment_path / Path('model.pt')\n",
    "    ckpt_path = experiment_path / Path('ckpt.pt')\n",
    "\n",
    "    # Modify parameters\n",
    "    if args.num_worker_override is not None:\n",
    "        param.Hardware.num_worker_train = args.num_worker_override\n",
    "\n",
    "    \"\"\"Hardware / Server stuff.\"\"\"\n",
    "    if args.device is not None:\n",
    "        device = args.device\n",
    "        # param.Hardware.device_simulation = device_overwrite  # lazy assumption\n",
    "    else:\n",
    "        device = param.Hardware.device\n",
    "\n",
    "    if args.data_path_override is not None:\n",
    "        param.InOut.data_path = args.data_path_override\n",
    "\n",
    "    if args.img_size_override is not None:\n",
    "        param.Simulation.img_size = [args.img_size_override,args.img_size_override]\n",
    "        param.Simulation.psf_extent = [[-0.5, args.img_size_override-0.5],\n",
    "                                       [-0.5, args.img_size_override-0.5], None]\n",
    "\n",
    "        param.TestSet.frame_extent = param.Simulation.psf_extent\n",
    "        param.TestSet.img_size = param.Simulation.img_size\n",
    "\n",
    "    # Backup the parameter file under the network output path with the experiments ID\n",
    "    param_backup_in = experiment_path / Path('param_run_in').with_suffix(param_file.suffix)\n",
    "    shutil.copy(param_file, param_backup_in)\n",
    "\n",
    "    param_backup = experiment_path / Path('param_run').with_suffix(param_file.suffix)\n",
    "    decode.utils.param_io.ParamHandling().write_params(param_backup, param)\n",
    "\n",
    "    if sys.platform in ('linux', 'darwin'):\n",
    "        os.nice(param.Hardware.unix_niceness)\n",
    "    elif param.Hardware.unix_niceness is not None:\n",
    "        print(f\"Cannot set niceness on platform {sys.platform}. You probably do not need to worry.\")\n",
    "\n",
    "    torch.set_num_threads(param.Hardware.torch_threads)\n",
    "\n",
    "    \"\"\"Setup Log System\"\"\"\n",
    "    if args.no_log:\n",
    "        logger = decode.neuralfitter.utils.logger.NoLog()\n",
    "\n",
    "    else:\n",
    "        log_folder = experiment_path\n",
    "\n",
    "        logger = decode.neuralfitter.utils.logger.MultiLogger(\n",
    "            [decode.neuralfitter.utils.logger.SummaryWriter(log_dir=log_folder,\n",
    "                                                            filter_keys=[\"dx_red_mu\", \"dx_red_sig\",\n",
    "                                                                         \"dy_red_mu\",\n",
    "                                                                         \"dy_red_sig\", \"dz_red_mu\",\n",
    "                                                                         \"dz_red_sig\",\n",
    "                                                                         \"dphot_red_mu\",\n",
    "                                                                         \"dphot_red_sig\"]),\n",
    "             decode.neuralfitter.utils.logger.DictLogger()])\n",
    "\n",
    "    # sim_train, sim_test = setup_random_simulation(param)\n",
    "    ds_train, ds_test, model, model_ls, optimizer, criterion, lr_scheduler, grad_mod, post_processor, matcher, ckpt = setup_trainer(logger, model_out, ckpt_path, device, param)\n",
    "    dl_train, dl_test = setup_dataloader(param, ds_train, ds_test)\n",
    "\n",
    "    if from_ckpt:\n",
    "        ckpt = decode.utils.checkpoint.CheckPoint.load(param.InOut.checkpoint_init)\n",
    "        model.load_state_dict(ckpt.model_state)\n",
    "        optimizer.load_state_dict(ckpt.optimizer_state)\n",
    "        lr_scheduler.load_state_dict(ckpt.lr_sched_state)\n",
    "        first_epoch = ckpt.step + 1\n",
    "        model = model.train()\n",
    "        print(f'Resuming training from checkpoint ' + experiment_id)\n",
    "    else:\n",
    "        first_epoch = 0\n",
    "\n",
    "    converges = False\n",
    "    n = 0\n",
    "    n_max = param.HyperParameter.auto_restart_param.num_restarts\n",
    "\n",
    "    while not converges and n < n_max:\n",
    "        n += 1\n",
    "\n",
    "        conv_check = decode.neuralfitter.utils.progress.GMMHeuristicCheck(\n",
    "            ref_epoch=1,\n",
    "            emitter_avg=param.Simulation.emitter_av,\n",
    "            threshold=param.HyperParameter.auto_restart_param.restart_treshold,\n",
    "        )\n",
    "\n",
    "        for i in range(first_epoch, param.HyperParameter.epochs):\n",
    "            logger.add_scalar('learning/learning_rate', optimizer.param_groups[0]['lr'], i)\n",
    "\n",
    "            if i >= 1:\n",
    "                _ = decode.neuralfitter.train_val_impl.train(\n",
    "                    model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    loss=criterion,\n",
    "                    dataloader=dl_train,\n",
    "                    grad_rescale=param.HyperParameter.moeller_gradient_rescale,\n",
    "                    grad_mod=grad_mod,\n",
    "                    epoch=i,\n",
    "                    device=torch.device(device),\n",
    "                    logger=logger\n",
    "                )\n",
    "\n",
    "            # val_loss=avg of loss for all batches\n",
    "            # test_out=list of network_output: [\"loss\", \"x\", \"y_out\", \"y_tar\", \"weight\", \"em_tar\"]\n",
    "            val_loss, test_out = decode.neuralfitter.train_val_impl.test(\n",
    "                model=model,\n",
    "                loss=criterion,\n",
    "                dataloader=dl_test,\n",
    "                epoch=i,\n",
    "                device=torch.device(device))\n",
    "\n",
    "            # check when first epoch\n",
    "            if not conv_check(test_out.loss[:, 0].mean(), i):\n",
    "                print(f\"The model will be reinitialized and retrained due to a pathological loss.\"\n",
    "                      f\"The max. allowed loss per emitter is {conv_check.threshold:.1f} vs.\"\n",
    "                      f\" {(test_out.loss[:, 0].mean() / conv_check.emitter_avg):.1f} (observed).\")\n",
    "\n",
    "                converges = False\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                converges = True\n",
    "\n",
    "            # if i%10 == 0:\n",
    "            \"\"\"Post-Process and Evaluate\"\"\"\n",
    "            log_train_val_progress.post_process_log_test(loss_cmp=test_out.loss,\n",
    "                                                        loss_scalar=val_loss,\n",
    "                                                        x=test_out.x, y_out=test_out.y_out,\n",
    "                                                        y_tar=test_out.y_tar,\n",
    "                                                        weight=test_out.weight,\n",
    "                                                        em_tar=ds_test.emitter(),\n",
    "                                                        px_border=-0.5, px_size=1.,\n",
    "                                                        post_processor=post_processor,\n",
    "                                                        matcher=matcher, logger=logger,\n",
    "                                                        step=i)\n",
    "            # else:\n",
    "            # log_train_val_progress.log_kpi_simplified(loss_scalar=val_loss,\n",
    "            #                                           loss_cmp=test_out.loss,\n",
    "            #                                           logger=logger,\n",
    "            #                                           step=i)\n",
    "\n",
    "\n",
    "            if i >= 1:\n",
    "                if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    lr_scheduler.step(val_loss)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "\n",
    "            model_ls.save(model, None)\n",
    "            if args.no_log:\n",
    "                ckpt.dump(model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict(),\n",
    "                          step=i)\n",
    "            else:\n",
    "                ckpt.dump(model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict(),\n",
    "                          log=logger.logger[1].log_dict, step=i)\n",
    "\n",
    "            \"\"\"Draw new samples Samples\"\"\"\n",
    "            # if param.Simulation.mode in 'acquisition':\n",
    "            #     ds_train.sample(True)\n",
    "            # elif param.Simulation.mode != 'samples':\n",
    "            #     raise ValueError\n",
    "\n",
    "    if converges:\n",
    "        print(\"Training finished after reaching maximum number of epochs.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Training aborted after {n_max} restarts. \"\n",
    "                         \"You can try to reduce the learning rate by a factor of 2.\"\n",
    "                         \"\\nIt is also possible that the simulated data is to challenging. \"\n",
    "                         \"Check if your background and intensity values are correct \"\n",
    "                         \"and possibly lower the average number of emitters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated.\n",
      "Model initialised as specified in the constructor.\n"
     ]
    }
   ],
   "source": [
    "# sim_train, sim_test = setup_random_simulation(param)\n",
    "ds_train, ds_test, model, model_ls, optimizer, criterion, lr_scheduler, grad_mod, post_processor, matcher, ckpt = setup_trainer(logger, model_out, ckpt_path, device, param)\n",
    "dl_train, dl_test = setup_dataloader(param, ds_train, ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lingjia/Documents/rPSF/NN/main_v2.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000006vscode-remote?line=0'>1</a>\u001b[0m root_dir \u001b[39m=\u001b[39m param\u001b[39m.\u001b[39mInOut\u001b[39m.\u001b[39mdata_path\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000006vscode-remote?line=1'>2</a>\u001b[0m train_IDs \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m,\u001b[39m9000\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000006vscode-remote?line=2'>3</a>\u001b[0m list_IDs \u001b[39m=\u001b[39m train_IDs\n",
      "\u001b[0;31mNameError\u001b[0m: name 'param' is not defined"
     ]
    }
   ],
   "source": [
    "root_dir = param.InOut.data_path\n",
    "train_IDs = numpy.arange(0,9000,1).tolist()\n",
    "list_IDs = train_IDs\n",
    "label_path = None\n",
    "label_path = label_path if label_path is not None else os.path.join(root_dir,'label.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "val_IDs = numpy.arange(9001,10001,1).tolist()\n",
    "\n",
    "label_path = '/media/hdd/rPSF_data/DECODE/simulation_figure4a_LD/label.txt'\n",
    "label_raw = numpy.loadtxt(label_path)\n",
    "import torch\n",
    "# print(label_raw.shape[0])\n",
    "# i_bol = [label_raw[ii,0] in val_IDs for ii in range(label_raw.shape[0])]\n",
    "i_bol = torch.zeros(label_raw.shape[0])\n",
    "for idx in val_IDs:\n",
    "    i_bol += label_raw[:,0] == idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "val_IDs = numpy.arange(9001,10001,1).tolist()\n",
    "list_IDs = val_IDs\n",
    "label_path = '/media/hdd/rPSF_data/DECODE/simulation_figure4a_LD/label.txt'\n",
    "\n",
    "label_raw = numpy.loadtxt(label_path)\n",
    "if label_raw.ndim < 2:\n",
    "    label_raw = numpy.expand_dims(label_raw, axis=0)\n",
    "\n",
    "i_bol = numpy.zeros(label_raw.shape[0],dtype=numpy.int8)\n",
    "for idx in list_IDs:\n",
    "    i_bol += label_raw[:,0] == idx\n",
    "\n",
    "# print(i_bol)\n",
    "label_raw_v2 = label_raw[i_bol>0,:]\n",
    "labels = torch.tensor(label_raw_v2[:,[0,4,1,2,3]]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "[[ 1.000000e+04  3.921390e+01  8.870000e+00  5.139500e+00  1.687187e+02]\n",
      " [ 1.000000e+04 -2.579060e+01 -3.792250e+01  3.359400e+00  1.186925e+02]\n",
      " [ 1.000000e+04 -8.237900e+00  5.469900e+00  2.333700e+00  9.225150e+01]]\n",
      "[[ 1.000000e+04  3.921390e+01  8.870000e+00  5.139500e+00  1.687187e+02]\n",
      " [ 1.000000e+04 -2.579060e+01 -3.792250e+01  3.359400e+00  1.186925e+02]\n",
      " [ 1.000000e+04 -8.237900e+00  5.469900e+00  2.333700e+00  9.225150e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(i_bol)\n",
    "print(label_raw[-3:,:])\n",
    "print(label_raw_v2[-3:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/hdd/rPSF_data/rPSF/train/0620_uniformFlux/label.txt\n",
      "[[  0.      20.4191  27.5939  -4.3109 113.561 ]\n",
      " [  0.     -24.3517 -25.3649   6.2191 105.108 ]\n",
      " [  0.      -5.3202  28.1096 -13.1525 139.0421]]\n",
      "tensor([[  0.0000, 113.5610,  68.4191,  75.5939,  -4.3109],\n",
      "        [  0.0000, 105.1080,  23.6483,  22.6351,   6.2191],\n",
      "        [  0.0000, 139.0421,  42.6798,  76.1096, -13.1525]])\n",
      "tensor(81.9998)\n",
      "tensor(81.9997)\n"
     ]
    }
   ],
   "source": [
    "print(label_path)\n",
    "label_raw = np.loadtxt(label_path)\n",
    "print(label_raw[:3,:])\n",
    "print(ds_train.label_gen()[:3,:])\n",
    "print(torch.max(ds_train.label_gen()[:,2]))\n",
    "print(torch.max(ds_train.label_gen()[:,3]))\n",
    "print(torch.max(ds_train.label_gen()[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load Parameters and back them up to the network output directory\"\"\"\n",
    "param_file = Path(args.param_file)\n",
    "param = decode.utils.param_io.ParamHandling().load_params(param_file)\n",
    "\n",
    "# auto-set some parameters (will be stored in the backup copy)\n",
    "# param = decode.utils.param_io.autoset_scaling(param)\n",
    "\n",
    "# add meta information - Meta=namespace(version='0.10.0'),\n",
    "param.Meta.version = decode.utils.bookkeeping.decode_state()\n",
    "\n",
    "\"\"\"Experiment ID\"\"\"\n",
    "if param.InOut.checkpoint_init is None:\n",
    "    experiment_id = datetime.datetime.now().strftime(\n",
    "        \"%Y-%m-%d_%H-%M-%S\") + '_' + socket.gethostname()\n",
    "    from_ckpt = False\n",
    "    if args.log_comment:\n",
    "        experiment_id = experiment_id + '_' + args.log_comment\n",
    "else:\n",
    "    from_ckpt = True\n",
    "    experiment_id = Path(param.InOut.checkpoint_init).parent.name\n",
    "\n",
    "\"\"\"Set up unique folder for experiment\"\"\"\n",
    "if not from_ckpt:\n",
    "    experiment_path = Path(param.InOut.experiment_out) / Path(experiment_id)\n",
    "else:\n",
    "    experiment_path = Path(param.InOut.checkpoint_init).parent\n",
    "\n",
    "if not experiment_path.parent.exists():\n",
    "    experiment_path.parent.mkdir()\n",
    "\n",
    "if not from_ckpt:\n",
    "    experiment_path.mkdir(exist_ok=False)\n",
    "\n",
    "model_out = experiment_path / Path('model.pt')\n",
    "ckpt_path = experiment_path / Path('ckpt.pt')\n",
    "\n",
    "# Modify parameters\n",
    "if args.num_worker_override is not None:\n",
    "    param.Hardware.num_worker_train = args.num_worker_override\n",
    "\n",
    "\"\"\"Hardware / Server stuff.\"\"\"\n",
    "if args.device is not None:\n",
    "    device = args.device\n",
    "    # param.Hardware.device_simulation = device_overwrite  # lazy assumption\n",
    "else:\n",
    "    device = param.Hardware.device\n",
    "\n",
    "if args.data_path_override is not None:\n",
    "    param.InOut.data_path = args.data_path_override\n",
    "\n",
    "if args.img_size_override is not None:\n",
    "    param.Simulation.img_size = [args.img_size_override,args.img_size_override]\n",
    "    param.Simulation.psf_extent = [[-0.5, args.img_size_override-0.5],\n",
    "                                    [-0.5, args.img_size_override-0.5], None]\n",
    "\n",
    "    param.TestSet.frame_extent = param.Simulation.psf_extent\n",
    "    param.TestSet.img_size = param.Simulation.img_size\n",
    "\n",
    "# Backup the parameter file under the network output path with the experiments ID\n",
    "param_backup_in = experiment_path / Path('param_run_in').with_suffix(param_file.suffix)\n",
    "shutil.copy(param_file, param_backup_in)\n",
    "\n",
    "param_backup = experiment_path / Path('param_run').with_suffix(param_file.suffix)\n",
    "decode.utils.param_io.ParamHandling().write_params(param_backup, param)\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     # device_ix = 1 if device='cuda:1', = None if device='cuda'\n",
    "#     _, device_ix = decode.utils.hardware._specific_device_by_str(device)\n",
    "#     if device_ix is not None:\n",
    "#         # do this instead of set env variable, because torch is inevitably already imported\n",
    "#         torch.cuda.set_device(device)\n",
    "# elif not torch.cuda.is_available():\n",
    "#     device = 'cpu'\n",
    "\n",
    "# \"\"\" Question \"\"\"\n",
    "# if param.Hardware.torch_multiprocessing_sharing_strategy is not None:\n",
    "#     torch.multiprocessing.set_sharing_strategy(\n",
    "#         param.Hardware.torch_multiprocessing_sharing_strategy)\n",
    "\n",
    "if sys.platform in ('linux', 'darwin'):\n",
    "    os.nice(param.Hardware.unix_niceness)\n",
    "elif param.Hardware.unix_niceness is not None:\n",
    "    print(f\"Cannot set niceness on platform {sys.platform}. You probably do not need to worry.\")\n",
    "\n",
    "torch.set_num_threads(param.Hardware.torch_threads)\n",
    "\n",
    "\"\"\"Setup Log System\"\"\"\n",
    "if args.no_log:\n",
    "    logger = decode.neuralfitter.utils.logger.NoLog()\n",
    "\n",
    "else:\n",
    "    log_folder = experiment_path\n",
    "\n",
    "    logger = decode.neuralfitter.utils.logger.MultiLogger(\n",
    "        [decode.neuralfitter.utils.logger.SummaryWriter(log_dir=log_folder,\n",
    "                                                        filter_keys=[\"dx_red_mu\", \"dx_red_sig\",\n",
    "                                                                        \"dy_red_mu\",\n",
    "                                                                        \"dy_red_sig\", \"dz_red_mu\",\n",
    "                                                                        \"dz_red_sig\",\n",
    "                                                                        \"dphot_red_mu\",\n",
    "                                                                        \"dphot_red_sig\"]),\n",
    "            decode.neuralfitter.utils.logger.DictLogger()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_train, sim_test = setup_random_simulation(param)\n",
    "ds_train, ds_test, model, model_ls, optimizer, criterion, lr_scheduler, grad_mod, post_processor, matcher, ckpt = setup_trainer(logger, model_out, ckpt_path, device, param)\n",
    "dl_train, dl_test = setup_dataloader(param, ds_train, ds_test)\n",
    "\n",
    "if from_ckpt:\n",
    "    ckpt = decode.utils.checkpoint.CheckPoint.load(param.InOut.checkpoint_init)\n",
    "    model.load_state_dict(ckpt.model_state)\n",
    "    optimizer.load_state_dict(ckpt.optimizer_state)\n",
    "    lr_scheduler.load_state_dict(ckpt.lr_sched_state)\n",
    "    first_epoch = ckpt.step + 1\n",
    "    model = model.train()\n",
    "    print(f'Resuming training from checkpoint ' + experiment_id)\n",
    "else:\n",
    "    first_epoch = 0\n",
    "\n",
    "converges = False\n",
    "n = 0\n",
    "n_max = param.HyperParameter.auto_restart_param.num_restarts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.add_scalar('learning/learning_rate', optimizer.param_groups[0]['lr'], i)\n",
    "\n",
    "_ = decode.neuralfitter.train_val_impl.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss=criterion,\n",
    "    dataloader=dl_train,\n",
    "    grad_rescale=param.HyperParameter.moeller_gradient_rescale,\n",
    "    grad_mod=grad_mod,\n",
    "    epoch=i,\n",
    "    device=torch.device(device),\n",
    "    logger=logger\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss=avg of loss for all batches\n",
    "# test_out=list of network_output: [\"loss\", \"x\", \"y_out\", \"y_tar\", \"weight\", \"em_tar\"]\n",
    "val_loss, test_out = decode.neuralfitter.train_val_impl.test(\n",
    "    model=model,\n",
    "    loss=criterion,\n",
    "    dataloader=dl_test,\n",
    "    epoch=i,\n",
    "    device=torch.device(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Post-Process and Evaluate\"\"\"\n",
    "log_train_val_progress.post_process_log_test(loss_cmp=test_out.loss,\n",
    "                                            loss_scalar=val_loss,\n",
    "                                            x=test_out.x, y_out=test_out.y_out,\n",
    "                                            y_tar=test_out.y_tar,\n",
    "                                            weight=test_out.weight,\n",
    "                                            em_tar=ds_test.emitter(),\n",
    "                                            px_border=-0.5, px_size=1.,\n",
    "                                            post_processor=post_processor,\n",
    "                                            matcher=matcher, logger=logger,\n",
    "                                            step=i)\n",
    "\n",
    "\n",
    "\n",
    "if i >= 1:\n",
    "    if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "        lr_scheduler.step(val_loss)\n",
    "    else:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "model_ls.save(model, None)\n",
    "if args.no_log:\n",
    "    ckpt.dump(model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict(),\n",
    "                step=i)\n",
    "else:\n",
    "    ckpt.dump(model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict(),\n",
    "                log=logger.logger[1].log_dict, step=i)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[68.4191, 75.5939, 15.6891],\n",
      "        [23.6483, 22.6351, 26.2191],\n",
      "        [42.6798, 76.1096,  6.8475]])\n",
      "tensor([113.5610, 105.1080, 139.0421])\n"
     ]
    }
   ],
   "source": [
    "print(ds_train.emitter().xyz[:3,:])\n",
    "# print(ds_train.emitter().frame_ix.shape)\n",
    "print(ds_train.emitter().phot[:3])\n",
    "# print(ds_train.emitter().bg.shape)\n",
    "# print(ds_train.emitter().get_subset_frame(1,1))\n",
    "# print(ds_train.emitter().frame_ix)\n",
    "\n",
    "# label_raw,path = ds_train.label_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[ 4.3076e-01,  5.1470e+01,  2.8865e+01,  6.1369e-01],\n",
    "        [ 5.9341e-01,  5.4971e+01,  1.6139e+01,  1.0704e+00],\n",
    "        [ 6.4862e-01,  4.3625e+01,  5.1123e+01, -1.0026e+00],\n",
    "        [ 5.3842e-01,  4.6118e+01,  2.4503e+01, -1.3809e+00],\n",
    "        [ 5.8623e-01,  7.2888e+01,  2.6713e+01,  1.6181e+00],\n",
    "        [ 4.4575e-01,  5.0563e+01,  4.2720e+01, -5.3808e-01],\n",
    "        [ 7.2379e-01,  4.6952e+01,  5.5178e+01,  3.2167e-01],\n",
    "        [ 7.1583e-01,  3.6665e+01,  4.7480e+01, -2.1770e-02],\n",
    "        [ 6.1125e-01,  5.3613e+01,  5.7800e+01,  1.2984e+00],\n",
    "        [ 6.1650e-01,  6.0197e+01,  7.6087e+01,  1.2360e-02],\n",
    "        [ 5.2857e-01,  5.1036e+01,  6.6435e+01,  6.8342e-01],\n",
    "        [ 6.2562e-01,  7.6063e+01,  3.3609e+01, -2.1582e-01],\n",
    "        [ 4.0985e-01,  6.7193e+01,  4.2250e+01, -1.7986e+00],\n",
    "        [ 4.5632e-01,  6.2332e+01,  3.6541e+01,  1.1406e+00],\n",
    "        [ 4.4718e-01,  2.0260e+01,  3.8910e+01,  1.9087e+00],\n",
    "        [ 7.1011e-01,  7.8753e+01,  3.5229e+01, -1.4820e+00],\n",
    "        [ 6.5208e-01,  2.9200e+01,  5.3470e+01, -1.8987e+00],\n",
    "        [ 6.7736e-01,  1.8492e+01,  2.1681e+01,  4.5164e-01],\n",
    "        [ 4.0185e-01,  1.8372e+01,  3.6160e+01, -1.8527e+00],\n",
    "        [ 5.4529e-01,  4.7004e+01,  7.1986e+01,  1.5167e+00],\n",
    "        [ 4.0989e-01,  1.5032e+01,  2.5290e+01,  1.6821e+00],\n",
    "        [ 4.8636e-01,  5.7208e+01,  4.6808e+01,  1.2659e+00],\n",
    "        [ 5.4032e-01,  5.0307e+01,  2.9100e+01,  8.7874e-01],\n",
    "        [ 6.2395e-01,  5.0439e+01,  2.7731e+01,  2.4122e-01],\n",
    "        [ 5.5494e-01,  5.0901e+01,  2.9253e+01,  2.4678e-01],\n",
    "        [ 6.2285e-01,  5.1220e+01,  2.9807e+01,  2.5108e-01],\n",
    "        [ 5.7925e-01,  4.9501e+01,  2.8861e+01,  4.6229e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([204818, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.1356e+02,  2.0419e+01,  2.7594e+01, -4.3109e+00],\n",
       "        [ 0.0000e+00,  1.0511e+02, -2.4352e+01, -2.5365e+01,  6.2191e+00],\n",
       "        [ 0.0000e+00,  1.3904e+02, -5.3202e+00,  2.8110e+01, -1.3153e+01],\n",
       "        ...,\n",
       "        [ 9.9990e+03,  1.1099e+02,  2.9010e+00, -1.8747e+01,  2.4678e+00],\n",
       "        [ 9.9990e+03,  1.2457e+02,  3.2202e+00, -1.8193e+01,  2.5108e+00],\n",
       "        [ 9.9990e+03,  1.1585e+02,  1.5008e+00, -1.9139e+01,  4.6229e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.label_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = 'im1.mat'\n",
    "aa.strip('im').strip('.mat')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32d9234fb3a060fbd30877034f28c0fca724fa3d0d25a605ad46b1806c555f07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('decode_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
