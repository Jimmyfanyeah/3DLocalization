{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import socket\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "import decode.evaluation\n",
    "import decode.neuralfitter\n",
    "import decode.neuralfitter.coord_transform\n",
    "import decode.neuralfitter.utils\n",
    "import decode.simulation\n",
    "import decode.utils\n",
    "from decode.neuralfitter.train.random_simulation import setup_random_simulation\n",
    "from decode.neuralfitter.utils import log_train_val_progress\n",
    "from decode.utils.checkpoint import CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Training Args')\n",
    "\n",
    "    parser.add_argument('-i', '--device', default=None,\n",
    "                        help='Specify the device string (cpu, cuda, cuda:0) and overwrite param.',\n",
    "                        type=str, required=False)\n",
    "\n",
    "    parser.add_argument('-p', '--param_file',\n",
    "                        help='Specify your parameter file (.yml or .json).',\n",
    "                        required=True)\n",
    "\n",
    "    parser.add_argument('-d', '--debug', default=False, action='store_true',\n",
    "                        help='Debug the specified parameter file. Will reduce ds size for example.')\n",
    "\n",
    "    parser.add_argument('-w', '--num_worker_override',\n",
    "                        help='Override the number of workers for the dataloaders.',\n",
    "                        type=int)\n",
    "\n",
    "    parser.add_argument('-n', '--no_log', default=False, action='store_true',\n",
    "                        help='Set no log if you do not want to log the current run.')\n",
    "\n",
    "    parser.add_argument('-l', '--log_folder', default='runs',\n",
    "                        help='Specify the (parent) folder you want to log to. If rel-path, relative to DECODE root.')\n",
    "\n",
    "    parser.add_argument('-c', '--log_comment', default=None,\n",
    "                        help='Add a log_comment to the run.')\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_file = '/home/lingjia/Documents/rPSF/NN/param_run.yaml'\n",
    "device_overwrite = 'cuda'\n",
    "debug = False\n",
    "num_worker_override = None\n",
    "no_log = False\n",
    "log_folder = '/home/lingjia/Documents/rPSF/log'\n",
    "log_comment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load Parameters and back them up to the network output directory\"\"\"\n",
    "param_file = Path(param_file)\n",
    "param = decode.utils.param_io.ParamHandling().load_params(param_file)\n",
    "\n",
    "# auto-set some parameters (will be stored in the backup copy)\n",
    "param = decode.utils.param_io.autoset_scaling(param)\n",
    "\n",
    "# add meta information\n",
    "param.Meta.version = decode.utils.bookkeeping.decode_state()\n",
    "\n",
    "\"\"\"Experiment ID\"\"\"\n",
    "if not debug:\n",
    "    if param.InOut.checkpoint_init is None:\n",
    "        experiment_id = datetime.datetime.now().strftime(\n",
    "            \"%Y-%m-%d_%H-%M-%S\") + '_' + socket.gethostname()\n",
    "        from_ckpt = False\n",
    "        if log_comment:\n",
    "            experiment_id = experiment_id + '_' + log_comment\n",
    "    else:\n",
    "        from_ckpt = True\n",
    "        experiment_id = Path(param.InOut.checkpoint_init).parent.name\n",
    "else:\n",
    "    experiment_id = 'debug'\n",
    "    from_ckpt = False\n",
    "\n",
    "\"\"\"Set up unique folder for experiment\"\"\"\n",
    "if not from_ckpt:\n",
    "    experiment_path = Path(param.InOut.experiment_out) / Path(experiment_id)\n",
    "else:\n",
    "    experiment_path = Path(param.InOut.checkpoint_init).parent\n",
    "\n",
    "if not experiment_path.parent.exists():\n",
    "    experiment_path.parent.mkdir()\n",
    "\n",
    "if not from_ckpt:\n",
    "    if debug:\n",
    "        experiment_path.mkdir(exist_ok=True)\n",
    "    else:\n",
    "        experiment_path.mkdir(exist_ok=False)\n",
    "\n",
    "model_out = experiment_path / Path('model.pt')\n",
    "ckpt_path = experiment_path / Path('ckpt.pt')\n",
    "\n",
    "# Backup the parameter file under the network output path with the experiments ID\n",
    "param_backup_in = experiment_path / Path('param_run_in').with_suffix(param_file.suffix)\n",
    "shutil.copy(param_file, param_backup_in)\n",
    "\n",
    "param_backup = experiment_path / Path('param_run').with_suffix(param_file.suffix)\n",
    "decode.utils.param_io.ParamHandling().write_params(param_backup, param)\n",
    "\n",
    "if debug:\n",
    "    decode.utils.param_io.ParamHandling.convert_param_debug(param)\n",
    "\n",
    "if num_worker_override is not None:\n",
    "    param.Hardware.num_worker_train = num_worker_override\n",
    "\n",
    "\"\"\"Hardware / Server stuff.\"\"\"\n",
    "if device_overwrite is not None:\n",
    "    device = device_overwrite\n",
    "    param.Hardware.device_simulation = device_overwrite  # lazy assumption\n",
    "else:\n",
    "    device = param.Hardware.device\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    _, device_ix = decode.utils.hardware._specific_device_by_str(device)\n",
    "    if device_ix is not None:\n",
    "        # do this instead of set env variable, because torch is inevitably already imported\n",
    "        torch.cuda.set_device(device)\n",
    "elif not torch.cuda.is_available():\n",
    "    device = 'cpu'\n",
    "\n",
    "if param.Hardware.torch_multiprocessing_sharing_strategy is not None:\n",
    "    torch.multiprocessing.set_sharing_strategy(\n",
    "        param.Hardware.torch_multiprocessing_sharing_strategy)\n",
    "\n",
    "if sys.platform in ('linux', 'darwin'):\n",
    "    os.nice(param.Hardware.unix_niceness)\n",
    "elif param.Hardware.unix_niceness is not None:\n",
    "    print(f\"Cannot set niceness on platform {sys.platform}. You probably do not need to worry.\")\n",
    "\n",
    "torch.set_num_threads(param.Hardware.torch_threads)\n",
    "\n",
    "\"\"\"Setup Log System\"\"\"\n",
    "if no_log:\n",
    "    logger = decode.neuralfitter.utils.logger.NoLog()\n",
    "\n",
    "else:\n",
    "    log_folder = log_folder + '/' + experiment_id\n",
    "\n",
    "    logger = decode.neuralfitter.utils.logger.MultiLogger(\n",
    "        [decode.neuralfitter.utils.logger.SummaryWriter(log_dir=log_folder,\n",
    "                                                        filter_keys=[\"dx_red_mu\", \"dx_red_sig\",\n",
    "                                                                        \"dy_red_mu\",\n",
    "                                                                        \"dy_red_sig\", \"dz_red_mu\",\n",
    "                                                                        \"dz_red_sig\",\n",
    "                                                                        \"dphot_red_mu\",\n",
    "                                                                        \"dphot_red_sig\"]),\n",
    "            decode.neuralfitter.utils.logger.DictLogger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_trainer(simulator_train, simulator_test, logger, model_out, ckpt_path, device, param):\n",
    "    \"\"\"Set model, optimiser, loss and schedulers\"\"\"\n",
    "    models_available = {\n",
    "        'SigmaMUNet': decode.neuralfitter.models.SigmaMUNet,\n",
    "        'DoubleMUnet': decode.neuralfitter.models.model_param.DoubleMUnet,\n",
    "        'SimpleSMLMNet': decode.neuralfitter.models.model_param.SimpleSMLMNet,\n",
    "    }\n",
    "\n",
    "    model = models_available[param.HyperParameter.architecture]\n",
    "    model = model.parse(param)\n",
    "\n",
    "    model_ls = decode.utils.model_io.LoadSaveModel(model,\n",
    "                                                   output_file=model_out)\n",
    "\n",
    "    model = model_ls.load_init()\n",
    "    model = model.to(torch.device(device))\n",
    "\n",
    "    # Small collection of optimisers\n",
    "    optimizer_available = {\n",
    "        'Adam': torch.optim.Adam,\n",
    "        'AdamW': torch.optim.AdamW\n",
    "    }\n",
    "\n",
    "    optimizer = optimizer_available[param.HyperParameter.optimizer]\n",
    "    optimizer = optimizer(model.parameters(), **param.HyperParameter.opt_param)\n",
    "\n",
    "    \"\"\"Loss function.\"\"\"\n",
    "    criterion = decode.neuralfitter.loss.GaussianMMLoss(\n",
    "        xextent=param.Simulation.psf_extent[0],\n",
    "        yextent=param.Simulation.psf_extent[1],\n",
    "        img_shape=param.Simulation.img_size,\n",
    "        device=device,\n",
    "        chweight_stat=param.HyperParameter.chweight_stat)\n",
    "\n",
    "    \"\"\"Learning Rate and Simulation Scheduling\"\"\"\n",
    "    lr_scheduler_available = {\n",
    "        'ReduceLROnPlateau': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        'StepLR': torch.optim.lr_scheduler.StepLR\n",
    "    }\n",
    "    lr_scheduler = lr_scheduler_available[param.HyperParameter.learning_rate_scheduler]\n",
    "    lr_scheduler = lr_scheduler(optimizer, **param.HyperParameter.learning_rate_scheduler_param)\n",
    "\n",
    "    \"\"\"Checkpointing\"\"\"\n",
    "    checkpoint = CheckPoint(path=ckpt_path)\n",
    "\n",
    "    \"\"\"Setup gradient modification\"\"\"\n",
    "    grad_mod = param.HyperParameter.grad_mod\n",
    "\n",
    "    \"\"\"Log the model\"\"\"\n",
    "    try:\n",
    "        dummy = torch.rand((2, param.HyperParameter.channels_in,\n",
    "                            *param.Simulation.img_size), requires_grad=False).to(\n",
    "            torch.device(device))\n",
    "        logger.add_graph(model, dummy)\n",
    "\n",
    "    except:\n",
    "        print(\"Did not log graph.\")\n",
    "        # raise RuntimeError(\"Your dummy input is wrong. Please update it.\")\n",
    "\n",
    "    \"\"\"Transform input data, compute weight mask and target data\"\"\"\n",
    "    frame_proc = decode.neuralfitter.scale_transform.AmplitudeRescale.parse(param)\n",
    "    bg_frame_proc = None\n",
    "\n",
    "    if param.HyperParameter.emitter_label_photon_min is not None:\n",
    "        em_filter = decode.neuralfitter.em_filter.PhotonFilter(\n",
    "            param.HyperParameter.emitter_label_photon_min)\n",
    "    else:\n",
    "        em_filter = decode.neuralfitter.em_filter.NoEmitterFilter()\n",
    "\n",
    "    tar_frame_ix_train = (0, 0)\n",
    "    tar_frame_ix_test = (0, param.TestSet.test_size)\n",
    "\n",
    "    \"\"\"Setup Target generator consisting possibly multiple steps in a transformation sequence.\"\"\"\n",
    "    tar_gen = decode.neuralfitter.utils.processing.TransformSequence(\n",
    "        [\n",
    "            decode.neuralfitter.target_generator.ParameterListTarget(\n",
    "                n_max=param.HyperParameter.max_number_targets,\n",
    "                xextent=param.Simulation.psf_extent[0],\n",
    "                yextent=param.Simulation.psf_extent[1],\n",
    "                ix_low=tar_frame_ix_train[0],\n",
    "                ix_high=tar_frame_ix_train[1],\n",
    "                squeeze_batch_dim=True),\n",
    "\n",
    "            decode.neuralfitter.target_generator.DisableAttributes.parse(param),\n",
    "\n",
    "            decode.neuralfitter.scale_transform.ParameterListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max)\n",
    "        ])\n",
    "\n",
    "    # setup target for test set in similar fashion, however test-set is static.\n",
    "    tar_gen_test = copy.deepcopy(tar_gen)\n",
    "    tar_gen_test.com[0].ix_low = tar_frame_ix_test[0]\n",
    "    tar_gen_test.com[0].ix_high = tar_frame_ix_test[1]\n",
    "    tar_gen_test.com[0].squeeze_batch_dim = False\n",
    "    tar_gen_test.com[0].sanity_check()\n",
    "\n",
    "    if param.Simulation.mode == 'acquisition':\n",
    "        train_ds = decode.neuralfitter.dataset.SMLMLiveDataset(\n",
    "            simulator=simulator_train,\n",
    "            em_proc=em_filter,\n",
    "            frame_proc=frame_proc,\n",
    "            bg_frame_proc=bg_frame_proc,\n",
    "            tar_gen=tar_gen, weight_gen=None,\n",
    "            frame_window=param.HyperParameter.channels_in,\n",
    "            pad=None, return_em=False)\n",
    "\n",
    "        train_ds.sample(True)\n",
    "\n",
    "    elif param.Simulation.mode == 'samples':\n",
    "        train_ds = decode.neuralfitter.dataset.SMLMLiveSampleDataset(\n",
    "            simulator=simulator_train,\n",
    "            em_proc=em_filter,\n",
    "            frame_proc=frame_proc,\n",
    "            bg_frame_proc=bg_frame_proc,\n",
    "            tar_gen=tar_gen,\n",
    "            weight_gen=None,\n",
    "            frame_window=param.HyperParameter.channels_in,\n",
    "            return_em=False,\n",
    "            ds_len=param.HyperParameter.pseudo_ds_size)\n",
    "\n",
    "    test_ds = decode.neuralfitter.dataset.SMLMAPrioriDataset(\n",
    "        simulator=simulator_test,\n",
    "        em_proc=em_filter,\n",
    "        frame_proc=frame_proc,\n",
    "        bg_frame_proc=bg_frame_proc,\n",
    "        tar_gen=tar_gen_test, weight_gen=None,\n",
    "        frame_window=param.HyperParameter.channels_in,\n",
    "        pad=None, return_em=False)\n",
    "\n",
    "    test_ds.sample(True)\n",
    "\n",
    "    \"\"\"Set up post processor\"\"\"\n",
    "    if param.PostProcessing is None:\n",
    "        post_processor = decode.neuralfitter.post_processing.NoPostProcessing(xy_unit='px',\n",
    "                                                                              px_size=param.Camera.px_size)\n",
    "\n",
    "    elif param.PostProcessing == 'LookUp':\n",
    "        post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "\n",
    "            decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max),\n",
    "\n",
    "            decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "            decode.neuralfitter.post_processing.LookUpPostProcessing(\n",
    "                raw_th=param.PostProcessingParam.raw_th,\n",
    "                pphotxyzbg_mapping=[0, 1, 2, 3, 4, -1],\n",
    "                xy_unit='px',\n",
    "                px_size=param.Camera.px_size)\n",
    "        ])\n",
    "\n",
    "    elif param.PostProcessing in ('SpatialIntegration', 'NMS'):  # NMS as legacy support\n",
    "        post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "\n",
    "            decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "                phot_max=param.Scaling.phot_max,\n",
    "                z_max=param.Scaling.z_max,\n",
    "                bg_max=param.Scaling.bg_max),\n",
    "\n",
    "            decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "            decode.neuralfitter.post_processing.SpatialIntegration(\n",
    "                raw_th=param.PostProcessingParam.raw_th,\n",
    "                xy_unit='px',\n",
    "                px_size=param.Camera.px_size)\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \"\"\"Evaluation Specification\"\"\"\n",
    "    matcher = decode.evaluation.match_emittersets.GreedyHungarianMatching.parse(param)\n",
    "\n",
    "    return train_ds, test_ds, model, model_ls, optimizer, criterion, lr_scheduler, grad_mod, post_processor, matcher, checkpoint\n",
    "\n",
    "\n",
    "def setup_dataloader(param, train_ds, test_ds=None):\n",
    "    \"\"\"Set's up dataloader\"\"\"\n",
    "\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        dataset=train_ds,\n",
    "        batch_size=param.HyperParameter.batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        num_workers=param.Hardware.num_worker_train,\n",
    "        pin_memory=True,\n",
    "        collate_fn=decode.neuralfitter.utils.dataloader_customs.smlm_collate)\n",
    "\n",
    "    if test_ds is not None:\n",
    "\n",
    "        test_dl = torch.utils.data.DataLoader(\n",
    "            dataset=test_ds,\n",
    "            batch_size=param.HyperParameter.batch_size,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            num_workers=param.Hardware.num_worker_train,\n",
    "            pin_memory=False,\n",
    "            collate_fn=decode.neuralfitter.utils.dataloader_customs.smlm_collate)\n",
    "    else:\n",
    "\n",
    "        test_dl = None\n",
    "\n",
    "    return train_dl, test_dl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated.\n",
      "Model initialised as specified in the constructor.\n",
      "Sampled dataset in 0.33s. 99786 emitters on 10001 frames.\n",
      "Sampled dataset in 0.02s. 5035 emitters on 513 frames.\n"
     ]
    }
   ],
   "source": [
    "sim_train, sim_test = setup_random_simulation(param)\n",
    "ds_train, ds_test, model, model_ls, optimizer, criterion, lr_scheduler, grad_mod, post_processor, matcher, ckpt = \\\n",
    "    setup_trainer(sim_train, sim_test, logger, model_out, ckpt_path, device, param)\n",
    "dl_train, dl_test = setup_dataloader(param, ds_train, ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "converges = False\n",
    "n = 0\n",
    "n_max = param.HyperParameter.auto_restart_param.num_restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E: 2 - t: 0.17 - t_dat: 0.00082 - L: 95.5: 100%|██████████| 156/156 [00:27<00:00,  5.68it/s]    \n"
     ]
    }
   ],
   "source": [
    "_ = decode.neuralfitter.train_val_impl.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss=criterion,\n",
    "    dataloader=dl_train,\n",
    "    grad_rescale=param.HyperParameter.moeller_gradient_rescale,\n",
    "    grad_mod=grad_mod,\n",
    "    epoch=i,\n",
    "    device=torch.device(device),\n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 40, 40])\n",
      "torch.Size([64, 250, 4])\n",
      "torch.Size([64, 250])\n",
      "torch.Size([64, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "dataloader = dl_test\n",
    "tqdm_enum = tqdm(dataloader, total=len(dataloader), smoothing=0.)  # progress bar enumeration\n",
    "ttt = iter(tqdm_enum)\n",
    "(x, y_tar, weight) = next(ttt)\n",
    "print(x.size())\n",
    "print(y_tar[0].size())\n",
    "print(y_tar[1].size())\n",
    "print(y_tar[2].size())\n",
    "# print(y_tar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Test) E: 2 - T: 0.59: 100%|██████████| 8/8 [00:00<00:00, 11.91it/s]\n"
     ]
    }
   ],
   "source": [
    "val_loss, test_out = decode.neuralfitter.train_val_impl.test(\n",
    "    model=model,\n",
    "    loss=criterion,\n",
    "    dataloader=dl_test,\n",
    "    epoch=i,\n",
    "    device=torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cmp=test_out.loss\n",
    "loss_scalar=val_loss\n",
    "x=test_out.x\n",
    "y_out=test_out.y_out\n",
    "y_tar=test_out.y_tar\n",
    "weight=test_out.weight\n",
    "em_tar=ds_test.emitter\n",
    "px_border=-0.5\n",
    "px_size=1.\n",
    "post_processor=post_processor\n",
    "matcher=matcher\n",
    "logger=logger\n",
    "step=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([511, 10, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "print(y_out.shape)\n",
    "y_out[:,0,:,:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([186, 510, 418,  ..., 431, 407, 424])\n",
      "4823\n",
      "tensor(510)\n",
      "511\n"
     ]
    }
   ],
   "source": [
    "print(ds_test.emitter.frame_ix)\n",
    "print(len(ds_test.emitter.frame_ix))\n",
    "print(ds_test.emitter.frame_ix.max())\n",
    "print(len(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([817600])\n",
      "torch.Size([817600, 3])\n",
      "torch.Size([817600, 3])\n",
      "torch.Size([817600])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Post-Process\"\"\"\n",
    "em_out, xyz, frame_ixx = post_processor.forward(y_out)\n",
    "# print(em_out.frame_ix)\n",
    "# print(em_out.xyz)\n",
    "# len(em_out.get_subset_frame(3,3).xyz)\n",
    "print(xyz.shape)\n",
    "print(frame_ixx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.6997e-01, -9.7671e-01,  6.7097e+02],\n",
      "        [ 9.4692e-01,  8.0565e-03,  9.2543e+02],\n",
      "        [ 9.4171e-01,  1.0031e+00,  8.9564e+02],\n",
      "        [ 9.7965e-01,  2.0030e+00,  9.1074e+02],\n",
      "        [ 9.9014e-01,  3.0060e+00,  9.1005e+02],\n",
      "        [ 9.8206e-01,  4.0024e+00,  8.5168e+02],\n",
      "        [ 9.8583e-01,  5.0025e+00,  8.4808e+02],\n",
      "        [ 9.8512e-01,  6.0028e+00,  8.5191e+02],\n",
      "        [ 9.8585e-01,  7.0026e+00,  8.4587e+02],\n",
      "        [ 9.8400e-01,  8.0027e+00,  8.4337e+02]])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(xyz[:10,:])\n",
    "print(frame_ixx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Match and Evaluate\"\"\"\n",
    "tp, fp, fn, tp_match = matcher.forward(em_out, em_tar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.000==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SMLMLiveDataset' object has no attribute 'emitters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/lingjia/Documents/rPSF/NN/main_decode.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_decode.ipynb#ch0000024vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# print(tp)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_decode.ipynb#ch0000024vscode-remote?line=1'>2</a>\u001b[0m \u001b[39m# print(fp)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_decode.ipynb#ch0000024vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m# print(fn)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_decode.ipynb#ch0000024vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m# print(tp_match)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_decode.ipynb#ch0000024vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(ds_train\u001b[39m.\u001b[39;49memitters)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SMLMLiveDataset' object has no attribute 'emitters'"
     ]
    }
   ],
   "source": [
    "# print(tp)\n",
    "# print(fp)\n",
    "# print(fn)\n",
    "# print(tp_match)\n",
    "print(ds_train.emitters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    result = evaluation.SMLMEvaluation(weighted_eval=WeightedErrors(mode='crlb', reduction='gaussian')).forward(tp, fp, fn, tp_match)\n",
    "\n",
    "\"\"\"Log\"\"\"\n",
    "# raw frames\n",
    "log_frames(x=x, y_out=y_out, y_tar=y_tar, weight=weight, em_out=em_out, em_tar=em_tar, tp=tp, tp_match=tp_match,\n",
    "            logger=logger, step=step)\n",
    "\n",
    "# KPIs\n",
    "log_kpi(loss_scalar=loss_scalar, loss_cmp=loss_cmp, eval_set=result._asdict(), logger=logger, step=step)\n",
    "\n",
    "# distributions\n",
    "log_dists(tp=tp, tp_match=tp_match, pred=em_out, px_border=px_border, px_size=px_size, logger=logger, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817600\n",
      "4938\n"
     ]
    }
   ],
   "source": [
    "output = em_out\n",
    "target = ds_test.emitter\n",
    "print(len(output))\n",
    "print(len(target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(output) >= 1 and len(target) >= 1:\n",
    "    frame_low = output.frame_ix.min() if output.frame_ix.min() < target.frame_ix.min() else target.frame_ix.min()\n",
    "    frame_high = output.frame_ix.max() if output.frame_ix.max() > target.frame_ix.max() else target.frame_ix.max()\n",
    "elif len(output) >= 1:\n",
    "    frame_low = output.frame_ix.min()\n",
    "    frame_high = output.frame_ix.max()\n",
    "elif len(target) >= 1:\n",
    "    frame_low = target.frame_ix.min()\n",
    "    frame_high = target.frame_ix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(510)\n"
     ]
    }
   ],
   "source": [
    "print(frame_low)\n",
    "print(frame_high)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32d9234fb3a060fbd30877034f28c0fca724fa3d0d25a605ad46b1806c555f07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('decode_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
