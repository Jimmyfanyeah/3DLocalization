{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from cmath import inf\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import socket\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import decode.evaluation\n",
    "import decode.neuralfitter\n",
    "import decode.neuralfitter.coord_transform\n",
    "import decode.neuralfitter.utils\n",
    "import decode.simulation\n",
    "import decode.utils\n",
    "# from decode.neuralfitter.train.random_simulation import setup_random_simulation\n",
    "from decode.neuralfitter.utils import log_train_val_progress\n",
    "from decode.utils.checkpoint import CheckPoint\n",
    "torch.set_printoptions(precision=4,sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Training Args')\n",
    "\n",
    "    parser.add_argument('-i', '--device', default=None, \n",
    "                        help='Specify the device string (cpu, cuda, cuda:0) and overwrite param.',\n",
    "                        type=str)\n",
    "\n",
    "    parser.add_argument('-p', '--param_file', default=None,\n",
    "                        help='Specify your parameter file (.yml or .json).', type=str)\n",
    "\n",
    "    parser.add_argument('-w', '--num_worker_override',default=None,\n",
    "                        help='Override the number of workers for the dataloaders.',\n",
    "                        type=int)\n",
    "\n",
    "    parser.add_argument('-n', '--no_log', default=False, action='store_true',\n",
    "                        help='Set no log if you do not want to log the current run.')\n",
    "\n",
    "    parser.add_argument('-c', '--log_comment', default=None,\n",
    "                        help='Add a log_comment to the run.')\n",
    "\n",
    "    parser.add_argument('-d', '--data_path_override', default=None,\n",
    "                        help='Specify your path to data', type=str)\n",
    "\n",
    "    parser.add_argument('-is', '--img_size_override', default=None,\n",
    "                        help='Override img size', type=int)\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "args = parse_args()\n",
    "args.device = 'cpu'\n",
    "args.param_file='/home/lingjia/Documents/rPSF/NN/param.yaml'\n",
    "# args.data_path_override='/media/hdd/rPSF/data/plain/train/0620_uniformFlux'\n",
    "args.img_size_override=96\n",
    "\n",
    "param_file = Path(args.param_file)\n",
    "param = decode.utils.param_io.ParamHandling().load_params(param_file)\n",
    "\n",
    "# add meta information - Meta=namespace(version='0.10.0'),\n",
    "param.Meta.version = decode.utils.bookkeeping.decode_state()\n",
    "\n",
    "\"\"\"Experiment ID\"\"\"\n",
    "if param.InOut.checkpoint_init is None:\n",
    "    experiment_id = datetime.datetime.now().strftime(\n",
    "        \"%Y-%m-%d-%H-%M-%S\") + '_' + socket.gethostname()\n",
    "    from_ckpt = False\n",
    "    if args.log_comment:\n",
    "        experiment_id = experiment_id + '_' + args.log_comment\n",
    "else:\n",
    "    from_ckpt = True\n",
    "    experiment_id = Path(param.InOut.checkpoint_init).parent.name\n",
    "\n",
    "\"\"\"Set up unique folder for experiment\"\"\"\n",
    "if not from_ckpt:\n",
    "    experiment_path = Path(param.InOut.experiment_out) / Path(experiment_id)\n",
    "else:\n",
    "    experiment_path = Path(param.InOut.checkpoint_init).parent\n",
    "\n",
    "if not experiment_path.parent.exists():\n",
    "    experiment_path.parent.mkdir()\n",
    "\n",
    "if not from_ckpt:\n",
    "    experiment_path.mkdir(exist_ok=False)\n",
    "\n",
    "model_out = experiment_path / Path('model.pt')\n",
    "ckpt_path = experiment_path / Path('ckpt.pt')\n",
    "\n",
    "# Modify parameters\n",
    "if args.num_worker_override is not None:\n",
    "    param.Hardware.num_worker_train = args.num_worker_override\n",
    "\n",
    "\"\"\"Hardware / Server stuff.\"\"\"\n",
    "if args.device is not None:\n",
    "    device = args.device\n",
    "    # param.Hardware.device_simulation = device_overwrite  # lazy assumption\n",
    "else:\n",
    "    device = param.Hardware.device\n",
    "\n",
    "if args.data_path_override is not None:\n",
    "    param.InOut.data_path = args.data_path_override\n",
    "\n",
    "if args.img_size_override is not None:\n",
    "    param.Simulation.img_size = [args.img_size_override,args.img_size_override]\n",
    "    param.Simulation.psf_extent = [[-0.5, args.img_size_override-0.5],\n",
    "                                    [-0.5, args.img_size_override-0.5], None]\n",
    "\n",
    "    param.TestSet.frame_extent = param.Simulation.psf_extent\n",
    "    param.TestSet.img_size = param.Simulation.img_size\n",
    "\n",
    "# Backup the parameter file under the network output path with the experiments ID\n",
    "param_backup_in = experiment_path / Path('param_run_in').with_suffix(param_file.suffix)\n",
    "# shutil.copy(param_file, param_backup_in)\n",
    "\n",
    "param_backup = experiment_path / Path('param_run').with_suffix(param_file.suffix)\n",
    "decode.utils.param_io.ParamHandling().write_params(param_backup, param)\n",
    "\n",
    "if sys.platform in ('linux', 'darwin'):\n",
    "    os.nice(param.Hardware.unix_niceness)\n",
    "elif param.Hardware.unix_niceness is not None:\n",
    "    print(f\"Cannot set niceness on platform {sys.platform}. You probably do not need to worry.\")\n",
    "\n",
    "torch.set_num_threads(param.Hardware.torch_threads)\n",
    "\n",
    "\"\"\"Setup Log System\"\"\"\n",
    "if args.no_log:\n",
    "    logger = decode.neuralfitter.utils.logger.NoLog()\n",
    "\n",
    "else:\n",
    "    log_folder = experiment_path\n",
    "\n",
    "    logger = decode.neuralfitter.utils.logger.MultiLogger(\n",
    "        [decode.neuralfitter.utils.logger.SummaryWriter(log_dir=log_folder,\n",
    "                                                        filter_keys=[\"dx_red_mu\", \"dx_red_sig\",\n",
    "                                                                        \"dy_red_mu\",\n",
    "                                                                        \"dy_red_sig\", \"dz_red_mu\",\n",
    "                                                                        \"dz_red_sig\",\n",
    "                                                                        \"dphot_red_mu\",\n",
    "                                                                        \"dphot_red_sig\"]),\n",
    "            decode.neuralfitter.utils.logger.DictLogger()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated.\n",
      "Model initialised as specified in the constructor.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Set model, optimiser, loss and schedulers\"\"\"\n",
    "models_available = {\n",
    "    'SigmaMUNet': decode.neuralfitter.models.SigmaMUNet,\n",
    "    'DoubleMUnet': decode.neuralfitter.models.model_param.DoubleMUnet,\n",
    "    'SimpleSMLMNet': decode.neuralfitter.models.model_param.SimpleSMLMNet,\n",
    "}\n",
    "\n",
    "model = models_available[param.HyperParameter.architecture]\n",
    "model = model.parse(param)\n",
    "\n",
    "model_ls = decode.utils.model_io.LoadSaveModel(model, output_file=model_out)\n",
    "\n",
    "model = model_ls.load_init()\n",
    "model = model.to(torch.device(device))\n",
    "\n",
    "# Small collection of optimisers\n",
    "optimizer_available = {\n",
    "    'Adam': torch.optim.Adam,\n",
    "    'AdamW': torch.optim.AdamW\n",
    "}\n",
    "\n",
    "optimizer = optimizer_available[param.HyperParameter.optimizer]\n",
    "optimizer = optimizer(model.parameters(), **param.HyperParameter.opt_param)\n",
    "\n",
    "\"\"\"Loss function.\"\"\"\n",
    "criterion = decode.neuralfitter.loss.GaussianMMLoss(\n",
    "    xextent=param.Simulation.psf_extent[0],\n",
    "    yextent=param.Simulation.psf_extent[1],\n",
    "    img_shape=param.Simulation.img_size,\n",
    "    device=device,\n",
    "    chweight_stat=param.HyperParameter.chweight_stat)\n",
    "\n",
    "\"\"\"Learning Rate and Simulation Scheduling\"\"\"\n",
    "lr_scheduler_available = {\n",
    "    'ReduceLROnPlateau': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    'StepLR': torch.optim.lr_scheduler.StepLR\n",
    "}\n",
    "lr_scheduler = lr_scheduler_available[param.HyperParameter.learning_rate_scheduler]\n",
    "lr_scheduler = lr_scheduler(optimizer, **param.HyperParameter.learning_rate_scheduler_param)\n",
    "\n",
    "\"\"\"Checkpointing\"\"\"\n",
    "checkpoint = CheckPoint(path=ckpt_path)\n",
    "\n",
    "\"\"\"Setup gradient modification\"\"\"\n",
    "grad_mod = param.HyperParameter.grad_mod\n",
    "\n",
    "\"\"\"Log the model (Graph) \"\"\"\n",
    "try:\n",
    "    dummy = torch.rand((2, param.HyperParameter.channels_in,\n",
    "                        *param.Simulation.img_size), requires_grad=False).to(torch.device(device))\n",
    "    logger.add_graph(model, dummy)\n",
    "\n",
    "except:\n",
    "    print(\"Did not log graph.\")\n",
    "    # raise RuntimeError(\"Your dummy input is wrong. Please update it.\")\n",
    "\n",
    "\"\"\"Setup Target generator consisting possibly multiple steps in a transformation sequence.\"\"\"\n",
    "tar_proc = decode.neuralfitter.utils.processing.TransformSequence(\n",
    "    [\n",
    "        # param_tar --> phot/max, z/z_max, bg/bg_max\n",
    "        decode.neuralfitter.scale_transform.ParameterListRescale(\n",
    "            phot_max=param.Scaling.phot_max,\n",
    "            z_max=param.Scaling.z_max,\n",
    "            bg_max=param.Scaling.bg_max)\n",
    "    ])\n",
    "\n",
    "# print(test_ds.label_gen())\n",
    "\n",
    "\"\"\"Set up post processor\"\"\"\n",
    "if param.PostProcessing is None:\n",
    "    post_processor = decode.neuralfitter.post_processing.NoPostProcessing(xy_unit='px',\n",
    "                                                                            px_size=param.Camera.px_size)\n",
    "\n",
    "elif param.PostProcessing == 'LookUp':\n",
    "    post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "\n",
    "        decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "            phot_max=param.Scaling.phot_max,\n",
    "            z_max=param.Scaling.z_max,\n",
    "            bg_max=param.Scaling.bg_max),\n",
    "\n",
    "        decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "        decode.neuralfitter.post_processing.LookUpPostProcessing(\n",
    "            raw_th=param.PostProcessingParam.raw_th,\n",
    "            pphotxyzbg_mapping=[0, 1, 2, 3, 4, -1],\n",
    "            xy_unit='px',\n",
    "            px_size=param.Camera.px_size)\n",
    "    ])\n",
    "\n",
    "elif param.PostProcessing in ('SpatialIntegration', 'NMS'):  # NMS as legacy support\n",
    "    post_processor = decode.neuralfitter.utils.processing.TransformSequence([\n",
    "        # out_tar --> out_tar: photo*photo_max, z*z_max, bg*bg_max\n",
    "        decode.neuralfitter.scale_transform.InverseParamListRescale(\n",
    "            phot_max=param.Scaling.phot_max,\n",
    "            z_max=param.Scaling.z_max,\n",
    "            bg_max=param.Scaling.bg_max),\n",
    "        # offset --> coordinate e.g., 0.2 --> 10.2 \n",
    "        decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),\n",
    "\n",
    "        decode.neuralfitter.post_processing.SpatialIntegration(\n",
    "            raw_th=param.PostProcessingParam.raw_th, # 0.5\n",
    "            xy_unit='px')\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_out: torch.Size([1, 10, 96, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingjia/anaconda3/envs/decode_dev/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([96, 96])) that is different to the input size (torch.Size([1, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1,1,96,96)\n",
    "y_out = model(x)\n",
    "print(f'y_out: {y_out.shape}')\n",
    "\n",
    "# define output, target, weight\n",
    "output = y_out\n",
    "\n",
    "param_tar = torch.zeros(1,100,4)\n",
    "param_tar_v = torch.randn(15,4)\n",
    "param_tar[0,:15,:] = param_tar_v\n",
    "\n",
    "mask_tar = torch.zeros(1,100,1)\n",
    "mask_tar[0,:15,:] = 1\n",
    "\n",
    "bg = torch.ones((96,96))*5\n",
    "target = (param_tar, mask_tar, bg)\n",
    "\n",
    "weight = None\n",
    "\n",
    "_forward_checks(output, target, weight)\n",
    "tar_param, tar_mask, tar_bg = target\n",
    "p, pxyz_mu, pxyz_sig, bg = _format_model_output(output)\n",
    "_bg_loss = torch.nn.MSELoss(reduction='none')\n",
    "bg_loss = _bg_loss(bg, tar_bg).sum(-1).sum(-1)\n",
    "# gmm_loss = _compute_gmm_loss(p, pxyz_mu, pxyz_sig, tar_param, tar_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 96])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod  # abstract class\n",
    "from typing import Union, Tuple\n",
    "\n",
    "import torch\n",
    "from deprecated import deprecated\n",
    "from torch import distributions\n",
    "\n",
    "# from . import MixtureSameFamily as mixture\n",
    "# from ..simulation import psf_kernel\n",
    "import decode.generic.utils\n",
    "\n",
    "p, pxyz_mu, pxyz_sig, pxyz_tar, mask = p, pxyz_mu, pxyz_sig, tar_param, tar_mask\n",
    "# def _compute_gmm_loss(self, p, pxyz_mu, pxyz_sig, pxyz_tar, mask) -> torch.Tensor:\n",
    "\"\"\"\n",
    "Computes the Gaussian Mixture Loss.\n",
    "\n",
    "Args:\n",
    "    p: the model's detection prediction (sigmoid already applied) size N x H x W\n",
    "    pxyz_mu: prediction of parameters (phot, xyz) size N x C=4 x H x W\n",
    "    pxyz_sig: presdiction of uncertainties / sigma values (phot, xyz) size N x C=4 x H x W\n",
    "    pxyz_tar: ground truth values (phot, xyz) size N x M x 4 (M being max number of tars)\n",
    "    mask: activation mask of ground truth values (phot, xyz) size N x M\n",
    "\n",
    "Returns:\n",
    "    torch.Tensor (size N x 1)\n",
    "\"\"\"\n",
    "\n",
    "batch_size = pxyz_mu.size(0)\n",
    "log_prob = 0\n",
    "print(p.shape)\n",
    "p_mean = p.sum(-1).sum(-1)\n",
    "p_var = (p - p ** 2).sum(-1).sum(-1)  # var estimate of bernoulli\n",
    "print(p_var.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_gauss = distributions.Normal(p_mean, torch.sqrt(p_var))\n",
    "\n",
    "log_prob = log_prob + p_gauss.log_prob(mask.sum(-1)) * mask.sum(-1)\n",
    "print(f'log_prob: {log_prob.shape}')\n",
    "# print(log_prob)\n",
    "prob_normed = p / p.sum(-1).sum(-1).view(-1, 1, 1)\n",
    "\n",
    "print(p.shape)\n",
    "p_inds = tuple((p + 1).nonzero(as_tuple=False).transpose(1, 0))\n",
    "# print(p_inds)\n",
    "print(pxyz_mu.shape)\n",
    "pxyz_mu = pxyz_mu[p_inds[0], :, p_inds[1], p_inds[2]]\n",
    "\n",
    "\n",
    "# p_inds = (torch.tensor([0,0]),torch.tensor([0,1]),torch.tensor([0,1]))\n",
    "# xx = torch.randn((1,3,3))\n",
    "# print(xx[p_inds[0], p_inds[1], p_inds[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Hacky way to get all prob indices\"\"\"\n",
    "p_inds = tuple((p + 1).nonzero(as_tuple=False).transpose(1, 0))\n",
    "pxyz_mu = pxyz_mu[p_inds[0], :, p_inds[1], p_inds[2]]\n",
    "\n",
    "\"\"\"Convert px shifts to absolute coordinates\"\"\"\n",
    "pxyz_mu[:, 1] += self.bin_ctr_x[p_inds[1]].to(pxyz_mu.device)\n",
    "pxyz_mu[:, 2] += self.bin_ctr_y[p_inds[2]].to(pxyz_mu.device)\n",
    "\n",
    "\"\"\"Flatten img dimension --> N x (HxW) x 4\"\"\"\n",
    "pxyz_mu = pxyz_mu.reshape(batch_size, -1, 4)\n",
    "pxyz_sig = pxyz_sig[p_inds[0], :, p_inds[1], p_inds[2]].reshape(batch_size, -1, 4)\n",
    "\n",
    "\"\"\"Set up mixture family\"\"\"\n",
    "mix = distributions.Categorical(prob_normed[p_inds].reshape(batch_size, -1))\n",
    "comp = distributions.Independent(distributions.Normal(pxyz_mu, pxyz_sig), 1)\n",
    "gmm = distributions.mixture_same_family.MixtureSameFamily(mix, comp)\n",
    "# print(f'gmm:{gmm}')\n",
    "\n",
    "\"\"\"Calc log probs if there is anything there\"\"\"\n",
    "if mask.sum():\n",
    "    # print(f'pxyz_tar:{pxyz_tar.shape}')\n",
    "    gmm_log = gmm.log_prob(pxyz_tar.transpose(0, 1)).transpose(0, 1)\n",
    "    gmm_log = (gmm_log * mask).sum(-1)\n",
    "    # print(f\"LogProb: {log_prob.mean()}, GMM_log: {gmm_log.mean()}\")\n",
    "    log_prob = log_prob + gmm_log\n",
    "\n",
    "# log_prob = log_prob.reshape(batch_size, 1)  # need?\n",
    "\n",
    "loss = log_prob * (-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _forward_checks(output: torch.Tensor, target: tuple, weight: None):\n",
    "\n",
    "    if weight is not None:\n",
    "        raise NotImplementedError(f\"Weight must be None for this loss implementation.\")\n",
    "\n",
    "    if output.dim() != 4:\n",
    "        raise ValueError(f\"Output must have 4 dimensions (N,C,H,W).\")\n",
    "\n",
    "    if output.size(1) != 10:\n",
    "        raise ValueError(f\"Wrong number of channels.\")\n",
    "\n",
    "    if len(target) != 3:\n",
    "        raise ValueError(f\"Wrong length of target.\")\n",
    "\n",
    "\n",
    "def _format_model_output(output: torch.Tensor) -> tuple:\n",
    "    \"\"\"\n",
    "    Transforms solely channel based model output into more meaningful variables.\n",
    "\n",
    "    Args:\n",
    "        output: model output\n",
    "\n",
    "    Returns:\n",
    "        tuple containing\n",
    "            p: N x H x W\n",
    "            pxyz_mu: N x 8 x H x W = phot1, phot2, phot3, x, y, z1, z2, z3\n",
    "            pxyz_sig: N x 8 x H x W = phot1, phot2, phot3, x, y, z1, z2, z3\n",
    "            bg: N x H x W\n",
    "    \"\"\"\n",
    "    p = output[:, 0]\n",
    "    pxyz_mu = output[:, 1:5]\n",
    "    pxyz_sig = output[:, 5:-1]\n",
    "    bg = output[:, -1]\n",
    "\n",
    "    return p, pxyz_mu, pxyz_sig, bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 Train Time:6.5e+01 Loss:2.41e+02: 100%|█████████████████████████| 281/281 [01:04<00:00,  4.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# for i in range(first_epoch, param.HyperParameter.epochs):\n",
    "i=1\n",
    "logger.add_scalar('learning/learning_rate', optimizer.param_groups[0]['lr'], i)\n",
    "print(f'Epoch{i}')\n",
    "\n",
    "if i >= 1:\n",
    "    _ = decode.neuralfitter.train_val_impl.train(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss=criterion,\n",
    "        dataloader=dl_train,\n",
    "        grad_rescale=param.HyperParameter.moeller_gradient_rescale,\n",
    "        grad_mod=grad_mod,\n",
    "        epoch=i,\n",
    "        device=torch.device(device),\n",
    "        logger=logger\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from typing import Union\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "\n",
    "from decode.neuralfitter.utils import log_train_val_progress\n",
    "from decode.evaluation.utils import MetricMeter\n",
    "from torch import distributions\n",
    "\n",
    "def ship_device(x, device: Union[str, torch.device]):\n",
    "    \"\"\"\n",
    "    Ships the input to a pytorch compatible device (e.g. CUDA)\n",
    "\n",
    "    Args:\n",
    "        x:\n",
    "        device:\n",
    "\n",
    "    Returns:\n",
    "        x\n",
    "\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return x\n",
    "\n",
    "    elif isinstance(x, torch.Tensor):\n",
    "        return x.to(device)\n",
    "\n",
    "    elif isinstance(x, (tuple, list)):\n",
    "        x = [ship_device(x_el, device) for x_el in x]  # a nice little recursion that worked at the first try\n",
    "        return x\n",
    "\n",
    "    elif device != 'cpu':\n",
    "        raise NotImplementedError(f\"Unsupported data type for shipping from host to CUDA device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lingjia/Documents/rPSF/NN/main_v2.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000007vscode-remote?line=4'>5</a>\u001b[0m grad_rescale\u001b[39m=\u001b[39mparam\u001b[39m.\u001b[39mHyperParameter\u001b[39m.\u001b[39mmoeller_gradient_rescale\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000007vscode-remote?line=5'>6</a>\u001b[0m grad_mod\u001b[39m=\u001b[39mgrad_mod\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000007vscode-remote?line=6'>7</a>\u001b[0m epoch\u001b[39m=\u001b[39mi\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000007vscode-remote?line=7'>8</a>\u001b[0m device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B144.214.74.91/home/lingjia/Documents/rPSF/NN/main_v2.ipynb#ch0000007vscode-remote?line=8'>9</a>\u001b[0m logger\u001b[39m=\u001b[39mlogger\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "model=model\n",
    "optimizer=optimizer\n",
    "loss=criterion\n",
    "dataloader=dl_train\n",
    "grad_rescale=param.HyperParameter.moeller_gradient_rescale\n",
    "grad_mod=grad_mod\n",
    "epoch=i\n",
    "device=torch.device(device)\n",
    "logger=logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/281 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Actual Training\"\"\"\n",
    "\"\"\"Some Setup things\"\"\"\n",
    "model.train()\n",
    "tqdm_enum = tqdm(dataloader, total=len(dataloader), smoothing=0.,ncols=100)  # progress bar enumeration\n",
    "t0 = time.time()\n",
    "loss_epoch = MetricMeter()\n",
    "loss_gmm_epoch = MetricMeter()\n",
    "loss_bg_epoch = MetricMeter()\n",
    "\n",
    "# for batch_num, (x, y_tar, weight) in enumerate(tqdm_enum):  # model input (x), target (yt), weights (w)\n",
    "    # x = frames, y_tar =  Tuple(param_tar, mask_tar, bg), weight = None\n",
    "batch_num, (x, y_tar, weight) = next(enumerate(tqdm_enum))\n",
    "# print(y_tar[0][0,:5,:])\n",
    "# print(y_tar[1][0,:5])\n",
    "# print(y_tar[1][0,-5:])\n",
    "# print(y_tar[2][0,:1,:1])\n",
    "# print(type(weight))\n",
    "\n",
    "\"\"\"Monitor time to get the data\"\"\"\n",
    "t_data = time.time() - t0\n",
    "\n",
    "\"\"\"Ship the data to the correct device\"\"\"\n",
    "x, y_tar, weight = ship_device([x, y_tar, weight], device)\n",
    "\n",
    "\"\"\"Forward the data\"\"\"\n",
    "y_out = model(x)\n",
    "# print(y_out.shape) # [32, 10, 96, 96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogProb: -1177.076416015625, GMM_log: 30.081775665283203\n",
      "tensor([ 1239.6512,     0.0309], device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = decode.neuralfitter.loss.GaussianMMLoss(\n",
    "    xextent=param.Simulation.psf_extent[0],\n",
    "    yextent=param.Simulation.psf_extent[1],\n",
    "    img_shape=param.Simulation.img_size,\n",
    "    device=device,\n",
    "    chweight_stat=param.HyperParameter.chweight_stat)\n",
    "\n",
    "\"\"\"Reset the optimiser, compute the loss and backprop it\"\"\"\n",
    "loss_val = loss(y_out, y_tar, weight)\n",
    "print(loss_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0309, device='cuda:2', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = y_out\n",
    "target = y_tar\n",
    "weight = weight\n",
    "\n",
    "# def forward(self, output: torch.Tensor, target: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n",
    "#             weight: None) -> torch.Tensor:\n",
    "\n",
    "tar_param, tar_mask, tar_bg = target\n",
    "# p, pxyz_mu, pxyz_sig, bg = self._format_model_output(output)\n",
    "p = output[:, 0]\n",
    "pxyz_mu = output[:, 1:5]\n",
    "pxyz_sig = output[:, 5:-1]\n",
    "bg = output[:, -1]\n",
    "# print(torch.max(p))\n",
    "# print(pxyz_mu.shape)\n",
    "\n",
    "\"\"\"\" Background Loss \"\"\"\n",
    "_bg_loss = torch.nn.MSELoss(reduction='none')\n",
    "bg_loss = _bg_loss(bg, tar_bg).sum(-1).sum(-1)\n",
    "print(bg_loss[0]*2)\n",
    "# print(torch.max(bg_loss))\n",
    "# print(bg[0,0,:5])\n",
    "# print(tar_bg[0,0,:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p\n",
    "pxyz_mu = pxyz_mu\n",
    "pxyz_sig = pxyz_sig\n",
    "pxyz_tar = tar_param\n",
    "mask = tar_mask\n",
    "\n",
    "batch_size = pxyz_mu.size(0) # 32\n",
    "log_prob = 0\n",
    "\n",
    "p_mean = p.sum(-1).sum(-1) # shape = [32]\n",
    "# print(p_mean)\n",
    "\n",
    "p_var = (p - p ** 2).sum(-1).sum(-1)  # var estimate of bernoulli\n",
    "# print(p_var)\n",
    "\n",
    "p_gauss = distributions.Normal(p_mean, torch.sqrt(p_var))\n",
    "# print(p_gauss.log_prob(mask.sum(-1)))\n",
    "# print(-((x - mu) ** 2) / (2 * sig**2) - math.log(sig) - math.log(math.sqrt(2 * math.pi)))\n",
    "\n",
    "# print(mask.sum(-1))\n",
    "# [39,  3,  1, 16,  3, 27, 12, 19,  4,  7,  5, 39, 27, 25, 28, 16, 19, 16,\n",
    "#          5, 37, 15, 23, 28,  2, 19, 19, 28,  7, 26,  3, 21,  8],\n",
    "#        device='cuda:2')\n",
    "\n",
    "log_prob = log_prob + p_gauss.log_prob(mask.sum(-1)) * mask.sum(-1)\n",
    "# print(log_prob)\n",
    "\n",
    "prob_normed = p / p.sum(-1).sum(-1).view(-1, 1, 1)\n",
    "# print(torch.max(prob_normed))\n",
    "# 0.1479"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-21.7802, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "tensor(641.6058, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "tensor(1239.6512, device='cuda:2', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "img_shape=param.Simulation.img_size\n",
    "xextent=param.Simulation.psf_extent[0]\n",
    "yextent=param.Simulation.psf_extent[1]\n",
    "_bin_x, _bin_y, bin_ctr_x, bin_ctr_y = decode.generic.utils.frame_grid(img_shape, xextent, yextent)\n",
    "\n",
    "p = output[:, 0]\n",
    "pxyz_mu = output[:, 1:5]\n",
    "pxyz_sig = output[:, 5:-1]\n",
    "\n",
    "\"\"\"Hacky way to get all prob indices\"\"\"\n",
    "p_inds = tuple((p + 1).nonzero(as_tuple=False).transpose(1, 0))\n",
    "pxyz_mu = pxyz_mu[p_inds[0], :, p_inds[1], p_inds[2]]\n",
    "\n",
    "\"\"\"Convert px shifts to absolute coordinates\"\"\"\n",
    "pxyz_mu[:, 1] += bin_ctr_x[p_inds[1]].to(pxyz_mu.device)\n",
    "pxyz_mu[:, 2] += bin_ctr_y[p_inds[2]].to(pxyz_mu.device)\n",
    "\n",
    "\"\"\"Flatten img dimension --> N x (HxW) x 4\"\"\"\n",
    "pxyz_mu = pxyz_mu.reshape(batch_size, -1, 4)\n",
    "pxyz_sig = pxyz_sig[p_inds[0], :, p_inds[1], p_inds[2]].reshape(batch_size, -1, 4)\n",
    "\n",
    "\"\"\"Set up mixture family\"\"\"\n",
    "mix = distributions.Categorical(prob_normed[p_inds].reshape(batch_size, -1))\n",
    "comp = distributions.Independent(distributions.Normal(pxyz_mu, pxyz_sig), 1)\n",
    "gmm = distributions.mixture_same_family.MixtureSameFamily(mix, comp)\n",
    "# print(f'gmm:{gmm}')\n",
    "\n",
    "\"\"\"Calc log probs if there is anything there\"\"\"\n",
    "if mask.sum():\n",
    "    # print(f'pxyz_tar:{pxyz_tar.shape}')\n",
    "    gmm_log = gmm.log_prob(pxyz_tar.transpose(0, 1)).transpose(0, 1)\n",
    "    gmm_log = (gmm_log * mask).sum(-1)\n",
    "    # print(f\"LogProb: {log_prob.mean()}, GMM_log: {gmm_log.mean()}\")\n",
    "    # log_prob = log_prob + gmm_log\n",
    "    gmm_loss = gmm_log\n",
    "\n",
    "# log_prob = log_prob.reshape(batch_size, 1)  # need?\n",
    "\n",
    "gmm_loss = gmm_loss * (-1)\n",
    "log_prob = log_prob * (-1)\n",
    "print(gmm_loss[0])\n",
    "print(log_prob[0])\n",
    "print((log_prob[0]+gmm_loss[0])*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-115.3188)\n",
      "-115.31881669101394\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "x = 39\n",
    "mu = 130.7310\n",
    "sig = math.sqrt(37.3684)\n",
    "\n",
    "p_gauss = distributions.Normal(mu,sig)\n",
    "print(p_gauss.log_prob(x))\n",
    "print(-((x - mu) ** 2) / (2 * sig**2) - math.log(sig) - math.log(math.sqrt(2 * math.pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grad_rescale:  # rescale gradients so that they are in the same order for the last layer\n",
    "    weight, _, _ = model.rescale_last_layer_grad(loss_val, optimizer)\n",
    "    loss_val = loss_val * weight\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss_val.mean().backward()\n",
    "\n",
    "\"\"\"Gradient Modification\"\"\"\n",
    "if grad_mod:\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.03, norm_type=2)\n",
    "\n",
    "\"\"\"Update model parameters\"\"\"\n",
    "optimizer.step()\n",
    "\n",
    "\"\"\"Monitor overall time\"\"\"\n",
    "t_batch = time.time() - t0\n",
    "\n",
    "\"\"\"Logging\"\"\"\n",
    "loss_mean, loss_cmp = loss.log(loss_val)  # compute individual loss components\n",
    "loss_gmm = loss_cmp['gmm']\n",
    "loss_bg = loss_cmp['bg']\n",
    "del loss_val\n",
    "loss_epoch.update(loss_mean)\n",
    "loss_gmm_epoch.update(loss_gmm)\n",
    "loss_bg_epoch.update(loss_bg)\n",
    "tqdm_enum.set_description(f\"{epoch} Train Time:{t_batch:.2} Loss:{loss_mean:.3}\")\n",
    "\n",
    "# t0 = time.time()\n",
    "\n",
    "# log_train_val_progress.log_train(loss_p_batch=loss_epoch.vals, loss_mean=loss_epoch.mean, logger=logger, step=epoch)\n",
    "\n",
    "log_train_val_progress.log_train(loss_p_batch=loss_epoch.vals, loss_mean=loss_epoch.mean, logger=logger, step=epoch,loss_gmm_mean=loss_gmm_epoch.mean,loss_bg_mean=loss_bg_epoch.mean)\n",
    "\n",
    "return loss_epoch.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# val_loss=avg of loss for all batches\n",
    "# test_out=list of network_output: [\"loss\", \"x\", \"y_out\", \"y_tar\", \"weight\", \"em_tar\"]\n",
    "val_loss, test_out = decode.neuralfitter.train_val_impl.test(\n",
    "    model=model,\n",
    "    loss=criterion,\n",
    "    dataloader=dl_test,\n",
    "    epoch=i,\n",
    "    device=torch.device(device))\n",
    "# print(val_loss)\n",
    "\n",
    "if best_val_loss - val_loss >1e-4:\n",
    "    best_val_loss = val_loss\n",
    "    # model_ls.save(model, None, epoch_idx='best')\n",
    "\n",
    "t0 = time.time()\n",
    "if i%3 == 0:\n",
    "    \"\"\"Post-Process and Evaluate\"\"\"\n",
    "    log_train_val_progress.post_process_log_test(loss_cmp=test_out.loss,\n",
    "                                                loss_scalar=val_loss,\n",
    "                                                x=test_out.x, y_out=test_out.y_out,\n",
    "                                                y_tar=test_out.y_tar,\n",
    "                                                weight=test_out.weight,\n",
    "                                                em_tar=ds_test.emitter(),\n",
    "                                                px_border=-0.5, px_size=1.,\n",
    "                                                post_processor=post_processor,\n",
    "                                                matcher=matcher, logger=logger,\n",
    "                                                step=i)\n",
    "else:\n",
    "    log_train_val_progress.log_kpi_simplified(loss_scalar=val_loss,\n",
    "                                            loss_cmp=test_out.loss,\n",
    "                                            logger=logger,\n",
    "                                            step=i)\n",
    "\n",
    "t_log = time.time() - t0\n",
    "print(f'log time:{t_log}')\n",
    "\n",
    "if i >= 1:\n",
    "    if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "        lr_scheduler.step(val_loss)\n",
    "    else:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "# print(\"Training finished after reaching maximum number of epochs.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32d9234fb3a060fbd30877034f28c0fca724fa3d0d25a605ad46b1806c555f07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('decode_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
